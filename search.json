[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "This workshop is taking place before the 2024 ASTMH conference in New Orleans, USA.\nüìç Where: Aloft New Orleans, 225 Baronne St, New Orleans, USA\nüóìÔ∏è When: 11-12 Nov 2024, immediately prior to the ASTMH conference"
  },
  {
    "objectID": "schedule.html#day-1",
    "href": "schedule.html#day-1",
    "title": "Schedule",
    "section": "Day 1",
    "text": "Day 1\n\n\n\nTime\nTitle\nFormat\n\n\n\n\n12:00-12:30\nLunch\nIn meeting room\n\n\n12:30-1:00\nIntro: Goal of MMS\nLecture\n\n\n1:00-1:45\nIntroductions\n\n\n\n1:45-2:15\nModule 1: Sampling from a population\nLecture\n\n\n2:15-3:00\nModule 1: Practical\nLearnR tutorial\n\n\n3:00-3:30\nBreak\n\n\n\n3:30-4:00\nModule 2: Sample size based on precision\nLecture\n\n\n4:00-4:45\nModule 2: Practical\nLearnR tutorial\n\n\n4:45:5:00\nBreak\n\n\n\n5:00-6:00\nDiscussion groups\nStructured discussion\n\n\n6pm onwards\nGroup dinner"
  },
  {
    "objectID": "schedule.html#day-2",
    "href": "schedule.html#day-2",
    "title": "Schedule",
    "section": "Day 2",
    "text": "Day 2\n\n\n\nTime\nTitle\nFormat\n\n\n\n\n8:30-9:00\nBreakfast\nIn meeting room\n\n\n9:00-9:05\nRecap of Day 1\n\n\n\n9:05-9:35\nGuest lecture: Logistics and challenges of designing a MMS study\nLecture\n\n\n9:35-10:05\nModule 3: Hypothesis testing, power and sample size calculation\nLecture\n\n\n10:05-10:50\nModule 3: Practical\nLearnR tutorial\n\n\n10:50-11:10\nBreak\n\n\n\n11:10-11:40\nModule 4: Intra-cluster correlation\nLecture\n\n\n11:40-12:30\nModule 4: Practical\nLearnR tutorial\n\n\n12:30-1:30\nLunch\n\n\n\n1:30-2:00\nModule 5: The DRpower tool\nLecture\n\n\n2:00-2:45\nModule 5: Practical\nLearnR tutorial\n\n\n2:45-3:00\nBreak\n\n\n\n3:00-3:15\nModule 6: Designing studies for multiple end-points\nLecture\n\n\n3:15-4:45\nModule 6: Practical\nRole play scenario\n\n\n4:45-5:30\nDiscussion and wrap-up"
  },
  {
    "objectID": "tutorials/module6/sheet_3.html",
    "href": "tutorials/module6/sheet_3.html",
    "title": "Fact sheet: health facility information",
    "section": "",
    "text": "As the budget officer on the team, your job is to help your team make informed decisions on costing and study design considerations, including:\n\nChoosing (and potentially limiting) the number of regions or health facilities.\nAdjusting sample sizes, number of clusters, and timelines.\nConducting cost calculations, for example:\n\nTotal Fixed Costs = Number of HFs √ó (Fixed Cost per HF + Transport Cost per HF)\nTotal Variable Costs = Total Samples Enrolled √ó Variable Cost per Sample Enrollment Rate\n\n\nDo your best job to stay within your budget!\n\n\n\n\n\n\n\n\n\n\nCost item\nCost\nDescription\n\n\n\n\nFixed cost per health facility enrolled\n$5,000\nIncludes training, equipment, and administrative expenses.\n\n\nCost per sample enrolled\n$50\nIncludes laboratory testing, consumables, and data management.\n\n\n\n\n\n\n\n\n\nRegion\nTransport cost per health facility\n\n\n\n\nNorth Region\n$1,000\n\n\nSouth Region\n$1,500\n\n\nEast Region\n$2,000\n\n\nWest Region\n$800"
  },
  {
    "objectID": "tutorials/module6/sheet_3.html#your-role",
    "href": "tutorials/module6/sheet_3.html#your-role",
    "title": "Fact sheet: health facility information",
    "section": "",
    "text": "As the budget officer on the team, your job is to help your team make informed decisions on costing and study design considerations, including:\n\nChoosing (and potentially limiting) the number of regions or health facilities.\nAdjusting sample sizes, number of clusters, and timelines.\nConducting cost calculations, for example:\n\nTotal Fixed Costs = Number of HFs √ó (Fixed Cost per HF + Transport Cost per HF)\nTotal Variable Costs = Total Samples Enrolled √ó Variable Cost per Sample Enrollment Rate\n\n\nDo your best job to stay within your budget!\n\n\n\n\n\n\n\n\n\n\nCost item\nCost\nDescription\n\n\n\n\nFixed cost per health facility enrolled\n$5,000\nIncludes training, equipment, and administrative expenses.\n\n\nCost per sample enrolled\n$50\nIncludes laboratory testing, consumables, and data management.\n\n\n\n\n\n\n\n\n\nRegion\nTransport cost per health facility\n\n\n\n\nNorth Region\n$1,000\n\n\nSouth Region\n$1,500\n\n\nEast Region\n$2,000\n\n\nWest Region\n$800"
  },
  {
    "objectID": "tutorials/module6/sheet_2_cb.html",
    "href": "tutorials/module6/sheet_2_cb.html",
    "title": "Fact sheet: Health facility coordinator",
    "section": "",
    "text": "As the health facility coordinator on the team, your job is to help your team make informed decisions on the target health facilities (cluster) and study design considerations, including:\n\nSelect appropriate regions and health facilities.\nDecide on the number of clusters (health facilities) to include.\nPlanning for the time it will take to enrol the total number of malaria-positive patients in each location.\n\nNavigate back to the group activity instructions if you need to!\nHealth facility information\nUse the buttons to download as .csv or .xls if you prefer"
  },
  {
    "objectID": "tutorials/module6/sheet_2_cb.html#your-role",
    "href": "tutorials/module6/sheet_2_cb.html#your-role",
    "title": "Fact sheet: Health facility coordinator",
    "section": "",
    "text": "As the health facility coordinator on the team, your job is to help your team make informed decisions on the target health facilities (cluster) and study design considerations, including:\n\nSelect appropriate regions and health facilities.\nDecide on the number of clusters (health facilities) to include.\nPlanning for the time it will take to enrol the total number of malaria-positive patients in each location.\n\nNavigate back to the group activity instructions if you need to!\nHealth facility information\nUse the buttons to download as .csv or .xls if you prefer"
  },
  {
    "objectID": "tutorials/module6/scenario2.html",
    "href": "tutorials/module6/scenario2.html",
    "title": "Scenario 2",
    "section": "",
    "text": "You have been recruited by the National Malaria Control Programme (NMCP) of Tanzania to assist with study design. The NMCP is concerned about the potential spread of mutations that affect the performance of HRP2-based rapid diagnostic tests (RDTs). pfhrp2 deletions can cause false-negative results in HRP2-based RDTs. In the last few weeks, there have been anecdotal reports of RDT failures in border towns, particularly in the South Region. Additionally, there are concerns about the emergence of artemisinin resistance due to pfk13 mutations, as neighboring countries have reported detection of these mutations. Confirming whether these rare mutations are present in Tanzania is a priority for the NMCP. The NMCP plans to conduct a cross-sectional study to estimate the prevalence of pfhrp2 deletions and detect pfk13 mutations. The NMCP are also interested to know the prevalence of other drug resistance mutations, such as pfdhps, pfdhfr and pfcrt mutations so these are secondary outcomes of interest."
  },
  {
    "objectID": "tutorials/module6/scenario2.html#background",
    "href": "tutorials/module6/scenario2.html#background",
    "title": "Scenario 2",
    "section": "",
    "text": "You have been recruited by the National Malaria Control Programme (NMCP) of Tanzania to assist with study design. The NMCP is concerned about the potential spread of mutations that affect the performance of HRP2-based rapid diagnostic tests (RDTs). pfhrp2 deletions can cause false-negative results in HRP2-based RDTs. In the last few weeks, there have been anecdotal reports of RDT failures in border towns, particularly in the South Region. Additionally, there are concerns about the emergence of artemisinin resistance due to pfk13 mutations, as neighboring countries have reported detection of these mutations. Confirming whether these rare mutations are present in Tanzania is a priority for the NMCP. The NMCP plans to conduct a cross-sectional study to estimate the prevalence of pfhrp2 deletions and detect pfk13 mutations. The NMCP are also interested to know the prevalence of other drug resistance mutations, such as pfdhps, pfdhfr and pfcrt mutations so these are secondary outcomes of interest."
  },
  {
    "objectID": "tutorials/module6/scenario2.html#your-task",
    "href": "tutorials/module6/scenario2.html#your-task",
    "title": "Scenario 2",
    "section": "Your task",
    "text": "Your task\nThe NMCP has a budget of USD 250,000. There are four regions in Tanzania (North, South, East and West) each with 25 health facilities. From previous studies conducted by the NMCP, we know that the intra-cluster correlation is 0.01. Your job is to design a study powered for the following end-points:\n\nPrimary endpoints\n\nEstimate the prevalence of pfhrp2 deletions causing false-negative RDTs\nDetect pfk13 mutations associated with artemisinin resistance.\n\nSecondary endpoint\n\nEstimate the prevalence of pfdhps, pfdhfr and pfcrt mutations.\n\n\nEach team member has key information on the epidemiological context, health facilities in each region, costing and sample size considerations (ICC, etc). Click on your role to access this information. Work in parellel (but together) to develop your study design!\n\n Epidemiologist: Provide insights on disease prevalence and high-risk areas.\n Health Facility Coordinator: Offer logistical information about facilities.\n Budget Officer: Manage financial aspects and calculate costs.\n Statistician (1-2 people): Handle sample size calculations and adjust for ICC."
  },
  {
    "objectID": "tutorials/module6/scenario4.html",
    "href": "tutorials/module6/scenario4.html",
    "title": "Scenario 3",
    "section": "",
    "text": "You have been recruited by the National Malaria Control Programme (NMCP) of Cambodia to assist with study design. The NMCP is concerned about the potential spread of mutations that affect the performance of HRP2-based rapid diagnostic tests (RDTs). pfhrp2 deletions can cause false-negative results in HRP2-based RDTs. In the last few weeks, there have been anecdotal reports of RDT failures in border towns, particularly in the Forest region. Additionally, there are concerns about the emergence of artemisinin resistance due to a new pfk13 mutation, as neighboring countries have reported its increasing prevalence. Confirming whether this rare mutation is present in Cambodia is a priority for the NMCP. The NMCP plans to conduct a cross-sectional study to estimate the prevalence of pfhrp2 deletions and detect the pfk13 mutation. The NMCP are also interested to know the prevalence of other drug resistance mutations, such as pfdhps, pfdhfr and pfcrt mutations so these are secondary outcomes of interest."
  },
  {
    "objectID": "tutorials/module6/scenario4.html#background",
    "href": "tutorials/module6/scenario4.html#background",
    "title": "Scenario 3",
    "section": "",
    "text": "You have been recruited by the National Malaria Control Programme (NMCP) of Cambodia to assist with study design. The NMCP is concerned about the potential spread of mutations that affect the performance of HRP2-based rapid diagnostic tests (RDTs). pfhrp2 deletions can cause false-negative results in HRP2-based RDTs. In the last few weeks, there have been anecdotal reports of RDT failures in border towns, particularly in the Forest region. Additionally, there are concerns about the emergence of artemisinin resistance due to a new pfk13 mutation, as neighboring countries have reported its increasing prevalence. Confirming whether this rare mutation is present in Cambodia is a priority for the NMCP. The NMCP plans to conduct a cross-sectional study to estimate the prevalence of pfhrp2 deletions and detect the pfk13 mutation. The NMCP are also interested to know the prevalence of other drug resistance mutations, such as pfdhps, pfdhfr and pfcrt mutations so these are secondary outcomes of interest."
  },
  {
    "objectID": "tutorials/module6/scenario4.html#your-task",
    "href": "tutorials/module6/scenario4.html#your-task",
    "title": "Scenario 3",
    "section": "Your task",
    "text": "Your task\nThe NMCP has a budget of USD 250,000. There are four regions in Cambodia (Coastal, Highland, Forest, and Urban) each with 25 health facilities. From previous studies conducted by the NMCP, we know that the intra-cluster correlation is 0.01. Your job is to design a study powered for the following end-points:\n\nPrimary endpoints\n\nEstimate the prevalence of pfhrp2 deletions causing false-negative RDTs\nDetect the new pfk13 mutation associated with artemisinin resistance.\n\nSecondary endpoint\n\nEstimate the prevalence of pfdhps, pfdhfr and pfcrt mutations.\n\n\nEach team member has key information on the epidemiological context, health facilities in each region, costing and sample size considerations (ICC, etc). Click on your role to access this information. Work in parellel (but together) to develop your study design!\n\n Epidemiologist: Provide insights on disease prevalence and high-risk areas.\n Health Facility Coordinator: Offer logistical information about facilities.\n Budget Officer: Manage financial aspects and calculate costs.\n Statistician (1-2 people): Handle sample size calculations and adjust for ICC."
  },
  {
    "objectID": "tutorials/module6/sheet_3_tz.html",
    "href": "tutorials/module6/sheet_3_tz.html",
    "title": "Fact sheet: Budget officer",
    "section": "",
    "text": "As the budget officer on the team, your job is to help your team make informed decisions on costing and study design considerations, including:\n\nChoosing (and potentially limiting) the number of regions or health facilities.\nAdjusting sample sizes, number of clusters, and timelines.\nConducting cost calculations, for example:\n\nTotal Fixed Costs = Number of HFs √ó (Fixed Cost per HF + Transport Cost per HF)\nTotal Variable Costs = Total Samples Enrolled √ó Variable Cost per Sample Enrollment Rate\n\n\nDo your best job to stay within your budget!\nNavigate back to the group activity instructions if you need to!\n\n\n\n\n\n\n\n\n\n\nCost item\nCost\nDescription\n\n\n\n\nFixed cost per health facility enrolled\n$5,000\nIncludes training, equipment, and administrative expenses.\n\n\nCost per sample enrolled\n$50\nIncludes collection, laboratory testing, consumables, and data management.\n\n\n\n\n\n\n\n\n\nRegion\nTransport cost per health facility\n\n\n\n\nNorth Region\n$1,000\n\n\nSouth Region\n$1,500\n\n\nEast Region\n$2,000\n\n\nWest Region\n$800"
  },
  {
    "objectID": "tutorials/module6/sheet_3_tz.html#your-role",
    "href": "tutorials/module6/sheet_3_tz.html#your-role",
    "title": "Fact sheet: Budget officer",
    "section": "",
    "text": "As the budget officer on the team, your job is to help your team make informed decisions on costing and study design considerations, including:\n\nChoosing (and potentially limiting) the number of regions or health facilities.\nAdjusting sample sizes, number of clusters, and timelines.\nConducting cost calculations, for example:\n\nTotal Fixed Costs = Number of HFs √ó (Fixed Cost per HF + Transport Cost per HF)\nTotal Variable Costs = Total Samples Enrolled √ó Variable Cost per Sample Enrollment Rate\n\n\nDo your best job to stay within your budget!\nNavigate back to the group activity instructions if you need to!\n\n\n\n\n\n\n\n\n\n\nCost item\nCost\nDescription\n\n\n\n\nFixed cost per health facility enrolled\n$5,000\nIncludes training, equipment, and administrative expenses.\n\n\nCost per sample enrolled\n$50\nIncludes collection, laboratory testing, consumables, and data management.\n\n\n\n\n\n\n\n\n\nRegion\nTransport cost per health facility\n\n\n\n\nNorth Region\n$1,000\n\n\nSouth Region\n$1,500\n\n\nEast Region\n$2,000\n\n\nWest Region\n$800"
  },
  {
    "objectID": "tutorials/module6/statistician_sheet_tz.html",
    "href": "tutorials/module6/statistician_sheet_tz.html",
    "title": "Fact sheet: Statistician",
    "section": "",
    "text": "As the statistician on the team, your job is to help your team make informed decisions on study design considerations, including:\n\nDecide on the number of clusters (health facilities) to include.\nBuffer for drop-out.\nDetermining the necessary sample size and power for primary and secondary endpoints.\nAdjust for ICC."
  },
  {
    "objectID": "tutorials/module6/statistician_sheet_tz.html#your-role",
    "href": "tutorials/module6/statistician_sheet_tz.html#your-role",
    "title": "Fact sheet: Statistician",
    "section": "",
    "text": "As the statistician on the team, your job is to help your team make informed decisions on study design considerations, including:\n\nDecide on the number of clusters (health facilities) to include.\nBuffer for drop-out.\nDetermining the necessary sample size and power for primary and secondary endpoints.\nAdjust for ICC."
  },
  {
    "objectID": "tutorials/module6/statistician_sheet_tz.html#available-data",
    "href": "tutorials/module6/statistician_sheet_tz.html#available-data",
    "title": "Fact sheet: Statistician",
    "section": "Available data",
    "text": "Available data\nIn order to help you perform these critical calculations, we have pre-loaded all the fact sheets and data that your various team members have access to.\nThis includes:\n\nepi: data on malaria prevalence, incidence and test positivity rate\nhealth_facilities: data on health facilities in each region, the population they serve, and expected malaria cases per month\n\ncost_per_hf: fixed cost per health facility enrolled (in USD), including training, equipment, and administrative expenses.\ncost_per_sample: cost per sample enrolled (in USD), including collection, laboratory testing, consumables, and data management\ncost_transport_north: transport cost per health facility (in USD) in the North region\ncost_transport_south: transport cost per health facility (in USD) in the South region\ncost_transport_east: transport cost per health facility (in USD) in the East region\ncost_transport_west: transport cost per health facility (in USD) in the West region\n\n\nExercise\nYou can use the below R code box to perform your calculations"
  },
  {
    "objectID": "tutorials/module6/module6_scenarios.html#introduction",
    "href": "tutorials/module6/module6_scenarios.html#introduction",
    "title": "Module 6: Designing a study for multiple end-points",
    "section": "Introduction",
    "text": "Introduction\nIn this module, you will design a study for multiple end-points with a scenario-based activity. Ideally this module would be completed in groups to encourage discussion but can also be completed individually. There is no right answer! This activity is meant to give you a chance to think about real-world scenarios and how you might design a study that is powered for more than one end-point. Take this opportunity to think about how you might balance between a study that is feasible within logistical and financial constraints and that provides the most useful information.\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is artificial and designed for teaching purposes only. It does not necessarily represent the real epidemiological situation in these locations.\n\nLearning Outcomes\nBy the end of this tutorial, you will be able to:\n\nConsider different aspects and epidemiological context when designing studies to balance statistical considerations and practical constraints\nDesign a study for multiple end-points tailored to a specific budget and ICC, and:\n\ncalculate power, sample size and margin of error of primary and secondary end-points\ndefine the number of clusters based on logistical and financial constraints\nbuffer for drop-out\nestimate total cost of study\n\n\n\n\nGroup activity instructions\n\nTeam roles\nEach member of the team can choose a specific ‚Äòrole‚Äô:\n\n Epidemiologist: Provide insights on disease prevalence and high-risk areas.\n Health Facility Coordinator: Offer logistical information about facilities.\n Budget Officer: Manage financial aspects and calculate costs.\n Statistician (1-2 people): Handle sample size calculations and adjust for ICC.\n\n\n\nChoose your scenario\n\n  Scenario 1 \n\n\n  Scenario 2 \n\n\n  Scenario 3 \n\n\n  Scenario 4 \n\n\n\nPresenting your study design\nAt the end of the activity, you will present your study design to the group. Prepare your 1-slide presentation following this template."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower_interactive.html",
    "href": "tutorials/module5/module5_DRpower_interactive.html",
    "title": "Module 5: The DRpower tool",
    "section": "",
    "text": "Welcome to Module 5: The DRpower tool.\nIn this module, we‚Äôll demonstrate the use of the DRpower R package and the accompanying web-based tool.\n\n\nIn this activity you will learn:\n\nHow to design a multi-cluster pfhrp2/3 deletion study.\nHow to analyse and interpret the results of a pfhrp2/3 deletion study.\nHow to account for intra-cluster correlation in other study designs, such as prevalence surveys and presence/absence studies.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is simulated for teaching purposes only. It does not necessarily represent the real epidemiological situation."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower_interactive.html#introduction",
    "href": "tutorials/module5/module5_DRpower_interactive.html#introduction",
    "title": "Module 5: The DRpower tool",
    "section": "",
    "text": "Welcome to Module 5: The DRpower tool.\nIn this module, we‚Äôll demonstrate the use of the DRpower R package and the accompanying web-based tool.\n\n\nIn this activity you will learn:\n\nHow to design a multi-cluster pfhrp2/3 deletion study.\nHow to analyse and interpret the results of a pfhrp2/3 deletion study.\nHow to account for intra-cluster correlation in other study designs, such as prevalence surveys and presence/absence studies.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is simulated for teaching purposes only. It does not necessarily represent the real epidemiological situation."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower_interactive.html#designing-a-multi-cluster-pfhrp23-deletion-study-in-ethiopia",
    "href": "tutorials/module5/module5_DRpower_interactive.html#designing-a-multi-cluster-pfhrp23-deletion-study-in-ethiopia",
    "title": "Module 5: The DRpower tool",
    "section": "Designing a multi-cluster pfhrp2/3 deletion study in Ethiopia",
    "text": "Designing a multi-cluster pfhrp2/3 deletion study in Ethiopia\n\nBackground\nYou have been tasked by the Ethiopian National Malaria Control Programme (NMCP) to assist with design and implementation of a study into pfhrp2/3 deletions. Following the WHO 2020 recommendation, this study will be multi-site and conducted at a regional level. It will establish whether the prevalence of pfhrp2 deletions among clinical malaria cases is significantly above the 5% threshold. If so, this will trigger a nationwide switch in rapid diagnostic tests (RDTs) away from tests that rely exclusively on the HRP2 protein.\nA full study of this sort would normally be run in parallel over multiple regions, however, for the purposes of this tutorial we will focus exclusively on the Amhara region.\n\n\nUsing sample size tables\nFirst, we need to scope out roughly how many sites and how many samples are required. The easiest way to do this is via pre-calculated sample size tables. Go to the pfhrp2/3 Planner and navigate to the Explore tab.\n\nYou should see a sample size table with the number of sites (health facilities) in rows, and the assumed prevalence of pfhrp2/3 deletions in columns (like below). The page automatically loads with the default ICC of 0.05 and the WHO 5% prevalence threshold.\n\nIn any power analysis, we must begin by assuming a known effect size under the alternative hypothesis. For this study, that means selecting an assumed prevalence of pfhrp2/3 deletions in the population. This assumption can be challenging and may feel somewhat arbitrary. It‚Äôs important to remember that as the assumed prevalence approaches the 5% detection threshold, the required sample size increases significantly. Conversely, assuming a very high prevalence may reduce the public health relevance of the study by focusing power on detecting only large shifts in the parasite population‚Äîchanges that could already be affecting clinical diagnosis.\nTo balance these factors, we recommend a default assumed prevalence of 10% (highlighted in purple). This value provides a reasonable sensitivity level while keeping sample sizes manageable. For more insights on selecting this parameter, refer to the FAQ section in the web-based pfhrp2/3 Planner.\n\n\nQUIZ - Sample sizes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs the number of sites recruited increases, the total sample size needed actually decreases. This may seem counterintuitive, as we might expect that adding more clusters would inherently make the study larger. What‚Äôs happening here is that with more clusters, the samples become more independent. By sampling from a greater number of distinct sites, we reduce the likelihood of repeatedly sampling from the same sub-population, thereby minimizing the impact of intra-cluster correlation. As a result, fewer samples are needed overall to achieve the same level of statistical power.\n\n\nFactoring in financial considerations\nThe Ethiopian NMCP has provided you with rough estimates of the costs of various aspects of the planned study, including the costs of RDT testing, microscopy, staff time, transport of samples and training of staff. They estimate it will cost $500 USD per health facility (cluster) recruited, plus an additional $6 USD per sample enrolled.\n\n\nQUIZ - Sample sizes based on cost\n\n\n\n\n\n\n\n\n\n\n\n\nThe design with 7 clusters comes in at $6,365 UDS total. This is made up of $3,500 for setting up the clusters plus $2,856 for the samples enrolled. This is the cheapest of the possible options, although between 6 and 10 clusters are quite similar total costs and may also be viable options.\n\n\nSelecting sites\nNext, we have to choose how we will select the 7 sites. Common choices are 1) sentinel site surveillance, where known and established sites are chosen based on feasibility, and 2) random selection, where a complete list of all health facilities is compiled and a defined number of sites is drawn at random from this list.\nSome advantages of sentinel site surveillance include:\n\nConsistency and Comparability Over Time: Sentinel sites are typically chosen for long-term monitoring, enabling consistent data collection over time. This allows for more precise trend analysis and easier comparisons of changes in disease prevalence.\nCost-Effectiveness and Established Infrastructure: Sentinel sites are often strategically chosen for accessibility and logistical ease, making them more cost-effective than random site selection, which may require travel to remote or difficult-to-reach locations. Additionally, these sites usually have established infrastructure, trained personnel, and local relationships, streamlining data collection and improving data quality.\nTargeting High-Burden or Priority Areas: Sentinel sites are often selected based on epidemiological significance, such as higher disease burden or strategic relevance for outbreak monitoring. This targeted approach can be advantageous in understanding and responding to disease patterns in high-risk areas, which might be overlooked in a random selection approach.\n\nOn the other hand, there are some advantages of random site selection:\n\nImproved Representativeness and Reduced Selection Bias: Random site selection from a complete list provides a more representative sample of the population and minimizes biases associated with known sentinel sites, which are often chosen based on specific criteria like accessibility or historical disease burden. This approach enhances the validity and generalizability of prevalence estimates, making them more applicable across various areas, including those not included in the survey.\nGreater Diversity of Environmental Conditions: Randomly selected sites are more likely to capture a range of environmental, socio-economic, and health system conditions. This variation is crucial for understanding factors that influence disease prevalence and for developing interventions that can apply across diverse settings.\n\n\n\nQUIZ - Study design\n\n\n\n\n\n\n\n\n\n\n\n\nFor the sake of this tutorial we will go with random selection of sites. A complete list of all health facilities in the Amhara region is compiled, and 7 sites are selected from this list at random. Table 1 gives the chosen sites and the target sample size based on our initial calculations.\n\n\n\n\n\n\n\n\n\nSite name\nSample size\n\n\n\n\nDese\n68\n\n\nMotta\n68\n\n\nDebark\n68\n\n\nMetema\n68\n\n\nChagni\n68\n\n\nFinote Selam\n68\n\n\nAlem Ketema\n68\n\n\n\n\nTable 1: target sample sizes based on initial exploration\n\n\n\n\n\n\n\n\n\n\n\nRefining sample sizes\nWith a preliminary study plan in place, we can now incorporate some real-world constraints. After discussions with site leads at each of the seven locations, we‚Äôve learned that several sites may face challenges in reaching the target sample size. This could stem from factors like limited staffing, low malaria incidence, or other local issues. To address this, you‚Äôve adjusted the sample sizes by increasing recruitment targets at sites where it is feasible to do so. Here‚Äôs the updated sample size table:\n\n\n\n\n\n\n\n\n\nSite name\nSample size\n\n\n\n\nDese\n100\n\n\nMotta\n30\n\n\nDebark\n70\n\n\nMetema\n55\n\n\nChagni\n90\n\n\nFinote Selam\n70\n\n\nAlem Ketema\n60\n\n\n\n\nTable 2: target sample sizes factoring in constraints\n\n\n\n\n\n\n\n\n\nBut now we are faced with a problem - how do we know if this new design still has adequate power? We can no longer rely on sample size tables, which assume the same sample size per cluster. On the other hand, we cannot simply assume that power will be adequate. This is where the Design tab of the pfhrp2/3 Planner becomes useful.\nDownload a .csv file with the current study plan from here. You can then upload this spreadsheet into the we app using the ‚ÄúUpload a .csv file‚Äù option. You should find that the table populates with these values.\n\nYou‚Äôll notice that drop-out is also considered at this stage. We are assuming 10% drop-out in each site, but for a more rigorous approach you may want to factor in different drop-out levels by site. When you click ‚ÄúCalculate adjusted sample sizes‚Äù you should see a table that contains the adjusted sample size, buffered for drop-out.\nNow we are ready to estimate power. On the same page you will find drop-down menus where you can set the assumed prevalence of pfhrp2/3 deletions and the intra-cluster correlation. When you hit the ‚ÄúEstimate power‚Äù button the tool will run a simulation-based power analysis (this may take a few seconds).\n\nBecause this result is simulation-based we only get an estimate of the power, and not an exact figure. If you want a more precise estimate you can try increasing the number of simulations, although this will take longer to run.\n\n\nQUIZ - Estimated power\n\n\n\n\n\n\n\n\n\n\n\n\nRunning an estimate with 1000 simulations should show that the study‚Äôs power is close to 80%, with the 95% confidence interval likely spanning this target. For future reference, you can download a copy of your power analysis from the ‚ÄúGenerate report‚Äù tab. Based on these results, the study plan appears statistically sound and ready for consideration. However, final approval should also take into account logistical and financial factors to ensure feasibility."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower_interactive.html#analyzing-pfhrp23-data",
    "href": "tutorials/module5/module5_DRpower_interactive.html#analyzing-pfhrp23-data",
    "title": "Module 5: The DRpower tool",
    "section": "Analyzing pfhrp2/3 data",
    "text": "Analyzing pfhrp2/3 data\nSome time later, the Ethiopian NMCP request your assistance once again to analyse the results of the pfhrp2/3 deletion study, which was carried out according to your plan. The results of the study are shown in Table 3.\n\n\n\n\n\n\n\n\n\n\nSite name\npfhrp2 negative\nSample size\n\n\n\n\nDese\n10\n100\n\n\nMotta\n1\n30\n\n\nDebark\n9\n70\n\n\nMetema\n7\n55\n\n\nChagni\n2\n90\n\n\nFinote Selam\n2\n70\n\n\nAlem Ketema\n8\n60\n\n\n\n\nTable 3: results of the pfhrp2/3 study\n\n\n\n\n\n\n\n\n\n\nYou can download these results in .csv form here. The easiest way to analyse these data is via the Analysis tab of the pfhrp2/3 Planner. Select ‚ÄúUpload a .csv file‚Äù and import the data.\n\nNow click the ‚ÄúEstimate prevalence‚Äù button to perform a Bayesian analysis of the data. This analysis takes into account the intra-cluster correlation in the data, which is estimated and accounted for in the prevalence estimate. Therefore there is no need to estimate a design effect or effective sample size as this is accounted for automatically.\nYou will also see a ‚ÄúProbability above threshold‚Äù field. This tells us the probability that the prevalence is above the 5% threshold.\n\n\nQUIZ - Probability above threshold\n\n\n\n\n\n\n\n\n\n\n\n\nIn this example, we have sufficient evidence to conclude that the prevalence of pfhrp2/3 deletions in the Amhara region is above the 5% threshold. Therefore, according to the WHO 2020 recommendation, we would be justified in switching RDTs to a brand that does not rely exclusively on the HRP2 protein.\n\nEstimating the ICC\nAs noted above, the DRpower method automatically accounts for ICC when estimating prevalence, so a separate ICC estimate is not strictly necessary. However, obtaining an ICC estimate can still be valuable for future study planning. It‚Äôs a straightforward process and contributes to a broader understanding of ICC levels, which can benefit researchers planning similar studies in the future or in neighbouring regions.\nStill on the Analysis tab, scroll down to the ‚ÄúEstimate ICC‚Äù button (it should look like the screenshot below). Clicking this button gives an estimate of the ICC, including a point estimate and a 95% Credible Interval (CrI).\n\n\n\nQUIZ - Intra-cluster correlation\n\n\n\n\n\n\n\n\n\n\n\n\nWe can navigate to the ‚ÄúGenerate report‚Äù tab to download a report detailing our analysis.\n\n\nRecap key points\nOur pfhrp2/3 analysis is now complete. We began with a well-powered study design, carefully crafted to be robust and realistic. By accounting for varying sample sizes across sites and anticipating potential drop-out, we reinforced the reliability of our approach. Beyond statistical considerations, we incorporated logistical and financial constraints to ensure the study‚Äôs feasibility. Importantly, we accounted for possible over-dispersion at both the design and analysis stages, increasing our confidence in the results. Ultimately, this rigorous approach allows us to conclude with confidence that the prevalence of pfhrp2/3 deletions exceeds the 5% threshold‚Äîa finding with significant implications for malaria control at the national level."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower_interactive.html#bonus-questions",
    "href": "tutorials/module5/module5_DRpower_interactive.html#bonus-questions",
    "title": "Module 5: The DRpower tool",
    "section": "Bonus questions",
    "text": "Bonus questions\nThe DRpower R package is primarily designed with pfhrp2/3 studies in mind, but also contains some functions that are useful for other multi-cluster designs. For example, it can be used when estimating prevalence to within a specified margin of error, or when detecting the presence of rare variants, while taking into account intra-cluster correlation. These features are only present in the R package, and are not present on the web-based pfhrp2/3 Planner.\nThe following R code calculates the sample size needed for a multi-cluster prevalence survey to reach a target margin of error. Try varying the value of the ICC and see how this impacts sample size.\n\n\n# calculate sample size needed to achieve a target MOE\nDRpower::get_sample_size_margin(MOE = 0.1, n_clust = 10, prevalence = 0.2, ICC = 0.01)\n\n\n\nThe result you obtain is the sample size needed per cluster to achieve your target MOE using the Wald interval.\nUntil now, we have focused on using the Wald interval to construct a 95% confidence interval (CI). Although the Wald interval is straightforward to calculate, it relies on assumptions that may not always hold. For instance, with a small sample size or when prevalence is near 0 or 1, the Wald interval can extend beyond logical boundaries, producing values below 0 or above 1. Such results are nonsensical and indicate that the interval may not accurately represent the underlying data.\nAn alternative approach is to use the Clopper-Pearson (CP) interval. Unlike the Wald interval, the CP interval remains within the 0 to 1 range, making it more statistically robust. However, this robustness comes with a trade-off: the CP interval tends to be conservative, resulting in wider intervals.\nPlay around with the following R code, which still aims to reach a target margin of error but now assuming CP intervals.\n\n  Reflection: \n What do you notice about the sample size compared to the simple Wald interval approach? \n\n\n\n# calculate sample size needed to achieve a target MOE using CP intervals\nDRpower::get_sample_size_margin_CP(MOE = 0.1, n_clust = 10, prevalence = 0.2, ICC = 0.01)\n\n\n\nThe result you obtain is the sample size needed per cluster to achieve your target MOE using the CP interval.\nFinally, we may want to look for the presence of rare variants in a multi-cluster design while accounting for intra-cluster correlation.\nPlay around with the following code.\n\n  Reflection: \n What total sample size would you need if you assume 10 clusters, 1% prevalence of the variant of interest, and an ICC of 0.05? How would this compare to the total sample size if you treated all sites as independent? \n\n\n\n# calculate sample size needed in a multi-cluster presence/absence study\nDRpower::get_sample_size_presence(n_clust = 5, prevalence = 0.05, ICC = 0.05)\n\n\n\nThe result you obtain is the sample size needed per cluster to detect the presence of rare variants at 1% prevalence."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_static.html",
    "href": "tutorials/module2/activity2_MOE_static.html",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "",
    "text": "This activity focuses on using margin of error arguments to come up with an appropriate sample size for a hypothetical study. In this activity you will learn:\n\nHow to calculate a 95% confidence interval from prevalence data\nHow to derive the formula for sample size directly from the confidence interval formula\nHow to calculate a minimum sample size using assumptions about prevalence and margin of error\nHow to account for drop-out and positive fraction\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is simulated for teaching purposes only. It does not necessarily represent the real epidemiological situation."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_static.html#learning-outcomes",
    "href": "tutorials/module2/activity2_MOE_static.html#learning-outcomes",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "",
    "text": "This activity focuses on using margin of error arguments to come up with an appropriate sample size for a hypothetical study. In this activity you will learn:\n\nHow to calculate a 95% confidence interval from prevalence data\nHow to derive the formula for sample size directly from the confidence interval formula\nHow to calculate a minimum sample size using assumptions about prevalence and margin of error\nHow to account for drop-out and positive fraction\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is simulated for teaching purposes only. It does not necessarily represent the real epidemiological situation."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_static.html#background",
    "href": "tutorials/module2/activity2_MOE_static.html#background",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Background",
    "text": "Background\nYou have been recruited by the National Malaria Control Programme (NMCP) of the Democratic Republic of the Congo (DRC) to assist with study design. The NMCP is concerned about the potential spread of mutations in the parasite population that confer partial resistance to the drug combination Sulfadoxine-Pyrimethamine (SP). The dhps K540E mutation, which is known to be associated with high level SP resistance alongside other common mutations, has recently been found at high prevalence (72%) in neighbouring Uganda. In the last few weeks there have been anecdotal reports of SP failure in Rutshuru town, which lies in Eastern DRC close to the border with Uganda, hence the NMCP is concerned about possible flow of drug resistant parasites over the border.\nThe NMCP plans to conduct a cross-sectional study to estimate the prevalence of the dhps K540E mutation within Rutshuru town. Your job is to work out the appropriate sample size for this study."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_static.html#results-of-a-pilot-study",
    "href": "tutorials/module2/activity2_MOE_static.html#results-of-a-pilot-study",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Results of a pilot study",
    "text": "Results of a pilot study\nThankfully, a pilot study has already been conducted in Rutshuru. This pilot study included 100 participants, chosen at random from households within the town, who were tested for malaria via rapid diagnostic test (RDT). 23 people tested positive for malaria and these samples were sent away for genetic sequencing. 19 samples were successfully sequenced, of which 5 were positive for the K540E mutation.\nQuestion: Which is the correct equation when calculating the prevalence of K540E mutations from the pilot data?\nOptions:\n\n23 / 100\n19 / 100\n5 / 23\n5 / 19 (correct)\n\nRecall that we can use the following formula to calculate a 95% confidence interval on our prevalence estimate:\n\\[\n\\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}}\n\\] Complete the following R code by entering the appropriate values for p and N to compute this interval:\n\n# enter values for the estimated prevalence and the sample size\np &lt;- 5 / 19 # NB, delete value\nN &lt;- 19     # NB, delete value\n\n# calculate the margin of error (MOE)\nz &lt;- qnorm(0.975)\nMOE &lt;- z*sqrt(p*(1 - p) / N)\n\n# report the point estimate and 95% confidence interval\ndata.frame(prevalence = p,\n           lower = p - MOE,\n           upper = p + MOE)\n\n  prevalence     lower     upper\n1  0.2631579 0.0651572 0.4611586\n\n\nQuestion: Which of these statements is correct:\nOptions:\n\nThe 95% CI ranges from 1.5% to 80.2%\nThe 95% CI ranges from 6.5% to 46.1% (correct)\nThe 95% CI ranges from 24.0% to 28.0%\nThe 95% CI ranges from 0.065% to 0.461%\n\nThe 95% CI shows that we are very uncertain of the prevalence of K540E mutations based on our pilot data alone. While our best estimate of the prevalence is 26%, the plausible range includes anything from 6.5% to 46.1%. The NMCP considers this range too wide to be useful. Hence, they plan to conduct a follow-up study."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_static.html#calculating-the-sample-size",
    "href": "tutorials/module2/activity2_MOE_static.html#calculating-the-sample-size",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Calculating the sample size",
    "text": "Calculating the sample size\nOur first task is to convert the formula for the margin of error (MOE) into a new formula that tells us the appropriate sample size. If you are comfortable with the mathematics and want to see how to do this then follow these steps. If not, you can jump ahead to Step 3 to see the final formula.\nStep 1: Write down the formula for the MOE\nWe will use the mathematical symbol \\(m\\) for the MOE:\n\\[\nm = z_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{N}}\n\\] Step 2: Square both sides\n\\[\nm^2 = z_{1-\\alpha/2}^2 \\frac{p(1-p)}{N}\n\\] Step 3: Multiply by \\(N\\) and divide by \\(m^2\\)\n\\[\nN = z_{1-\\alpha/2}^2 \\frac{p(1-p)}{m^2}\n\\] We can use this formula to tell us the appropriate sample size given an assumed value of the prevalence (\\(p\\)) and a target value for the MOE (\\(m\\)).\nQuestion: What value should we assume for \\(p\\)?\nOptions: (all three answers are correct as they are all reasonable)\n\n0.26 based on the pilot data\n0.5 as this is the most pessimistic assumption in terms of requiring the largest sample size\n0.72 based on the prevalence in neighbouring Uganda\n\nAll three answers above are reasonable as long as they can be justified. But for the sake of argument let‚Äôs assume a value of \\(p=0.26\\). The NMCP has decided that a MOE of 5% is acceptable. Complete the following R code by entering the appropriate values for p and m to compute the resulting sample size:\n\n# enter values for the estimated prevalence and the sample size\np &lt;- 0.26     # NB, delete value\nm &lt;- 0.05     # NB, delete value\n\n# calculate the raw sample size\nz &lt;- qnorm(0.975)\nN &lt;- z^2*p*(1 - p) / m^2\n\nprint(N)\n\n[1] 295.6387\n\n\nYou should have obtained a sample size of 295.64, which we would round up to \\(N=296\\) to give a whole number. The nice thing about this calculation is that we can double check that it is correct. Try entering the values \\(p=0.26\\) and \\(N=296\\) into the 95% CI formula that we used in the pilot data analysis. If our calculations were correct, you should find that the resulting MOE is very close to 5%."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_static.html#buffering",
    "href": "tutorials/module2/activity2_MOE_static.html#buffering",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Buffering",
    "text": "Buffering\nBuffering refers to increasing a sample size to allow for events that are out of our control and that can result in drop-out (loss of samples). Some ways that drop-out can occur are through:\n\nParticipants withdrawing consent\nParticipants dying or leaving the area\nSamples being lost during transportation\nSamples becoming contaminated\nSamples failing amplification or sequencing resulting in a lack of genetic data\nData being lost due to computational errors\n\nWe cannot completely eliminate the risk of drop-out, but by buffering sample sizes we can be robust to it. If we expect a proportion \\(d\\) of samples to be lost, then the formula for adjusted sample size is:\n\\[\nN_{\\text{buffered}} = \\frac{N_{\\text{original}}}{1 - d}\n\\]\nThrough consulting with lab technicians and the study team, you estimate that 10% of samples may be lost to drop-out. Complete the following R code to come up with a buffered sample size:\n\n# enter value for estimated dropout\nr &lt;- 0.1     # NB, delete value\n\n# calculate the buffered sample size\nN_buffered &lt;- N / (1 - r)\n\nprint(N_buffered)\n\n[1] 328.4874\n\n\nQuestion: What is the correct buffered sample size?\nOptions:\n\n300\n328\n350\n329 (correct)"
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_static.html#accounting-for-positive-fraction",
    "href": "tutorials/module2/activity2_MOE_static.html#accounting-for-positive-fraction",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Accounting for positive fraction",
    "text": "Accounting for positive fraction\nSo far, we have focused on working out how many confirmed malaria cases we need in our study. However, recall that this will be a cross-sectional study with individuals being sampled at random from households within Rutshuru town. Many of the individuals tested will not be positive for malaria. It may be useful for us to know how many individuals we need to test as part of this study, which may be considerably higher than the number of confirmed malaria cases.\nThe NMCP estimates that 25% of the population of Rutshuru will be positive for malaria by RDT. We can use the same buffering formula as before, but now using the positive fraction (\\(f\\)) to inflate our sample size:\n\\[\nN_{\\text{test}} = \\frac{N_{\\text{confirmed}}}{f}\n\\]\nComplete the following R code to work out the number of people we will need to test to achieve the final target sample size:\n\n# enter value for estimated positive fraction\nN_buffered &lt;- 329\nf &lt;- 0.25     # NB, delete value\n\n# calculate the testing sample size\nN_test &lt;- N_buffered / f\n\nprint(N_test)\n\n[1] 1316\n\n\nQuestion: How many people will we need to test to obtain the target sample size of 329 positive malaria cases?\nOptions:\n\n534\n923\n1316 (correct)\n1536\n\nYou have now completed your study design exercise. Your recommendation to the NMCP is as follows:\nAssuming a prevalence of K540E mutations of 26% based on pilot data, a sample size of 329 confirmed malaria cases will be needed to estimate prevalence to within 5% margin of error. This number is buffered to take into account an assumed 10% drop-out. Assuming that malaria prevalence is 25% by RDT in Rutshuru town, this translates to 1316 individuals who will need to be tested in the cross-sectional study design."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_static.html#bonus-questions",
    "href": "tutorials/module2/activity2_MOE_static.html#bonus-questions",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Bonus questions",
    "text": "Bonus questions\nThe study design above is based on strong statistical principles. However, it is worth testing how robust these numbers are to changes in our assumptions.\n\nUnder the chosen sample size of 296 (after drop-out), what would be your margin of error under the worst case scenario that the true prevalence of the K540E mutation was actually 50%?\nWe estimated that 1316 people will need to be tested based on an assumed 25% prevalence of malaria. But what if malaria prevalence is actually only 15% in Rutshuru town?"
  },
  {
    "objectID": "tutorials/module3/activity3_power_static.html",
    "href": "tutorials/module3/activity3_power_static.html",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "",
    "text": "This activity focuses on hypothesis testing and power. After a short quiz, you will work through two examples; 1) detecting a change in prevalence over time, and 2) looking to detect rare variants. In this activity you will learn:\n\nSome key definitions around null hypothesis testing.\nHow to use a test statistic to decide whether or not to reject a null hypothesis.\nHow to perform power analysis under two different statistical tests, and how to use this to select sample sizes.\nHow to interpret power curves.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is simulated for teaching purposes only. It does not necessarily represent the real epidemiological situation."
  },
  {
    "objectID": "tutorials/module3/activity3_power_static.html#learning-outcomes",
    "href": "tutorials/module3/activity3_power_static.html#learning-outcomes",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "",
    "text": "This activity focuses on hypothesis testing and power. After a short quiz, you will work through two examples; 1) detecting a change in prevalence over time, and 2) looking to detect rare variants. In this activity you will learn:\n\nSome key definitions around null hypothesis testing.\nHow to use a test statistic to decide whether or not to reject a null hypothesis.\nHow to perform power analysis under two different statistical tests, and how to use this to select sample sizes.\nHow to interpret power curves.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is simulated for teaching purposes only. It does not necessarily represent the real epidemiological situation."
  },
  {
    "objectID": "tutorials/module3/activity3_power_static.html#short-quiz-on-hypothesis-testing-and-power",
    "href": "tutorials/module3/activity3_power_static.html#short-quiz-on-hypothesis-testing-and-power",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "Short quiz on hypothesis testing and power",
    "text": "Short quiz on hypothesis testing and power\nQuestion: What is a null hypothesis?\nOptions:\n\nA statement that there is a significant effect or difference between groups.\nA prediction about the future outcome of an experiment.\nA statement that there is no effect or no difference between groups, and any observed effect is due to chance. (correct)\nA hypothesis that describes the expected relationship between two variables.\n\nQuestion: Which of these is not a null hypothesis?\nOptions:\n\nThere is no difference in malaria prevalence between people who sleep under bed-nets and people who do not.\nThe presence of a genetic marker for drug resistance is independent of the region (e.g., East Africa vs.¬†West Africa).\nElevation has no linear relationship with malaria risk.\nMalaria incidence is twice as high in men as it is in women. (correct)\n\nQuestion: A false-negative result is when‚Ä¶(this one takes some thinking)\nOptions:\n\n\nYou fail to reject the null hypothesis when it is actually false. (correct)\n\n\nYou fail to reject the null hypothesis when it is actually true.\n\n\nYou reject the null hypothesis when it is actually false.\n\n\nYou reject the null hypothesis when it is actually true.\n\n\nAnswer: This type of question is always tricky as the language is all quite similar. Remember that a ‚Äúnegative‚Äù result means we fail to reject the null hypothesis. We were looking for something interesting, we didn‚Äôt find it, so we stick with the null. This means we can narrow down the answer to A) or B). Now consider that the question was about a ‚Äúfalse-negative‚Äù, meaning we came to the incorrect conclusion. This means the null hypothesis must have actually been false, and we made the wrong choice by failing to reject it. Therefore, the answer is A).\nQuestion: The parameter \\(\\alpha\\) is often referred to as‚Ä¶\nOptions:\n\nThe confidence level of a hypothesis test.\nThe significance level of a hypothesis test. (correct)\nThe power of a statistical test.\nThe probability of making a Type II error.\n\nQuestion: The value of \\(\\alpha\\) defines‚Ä¶\nOptions:\n\nThe sample size of our study.\nThe chance of getting a false-negative result (also known as a Type II error).\nThe strength of the effect we observe.\nThe chance of getting a false-positive result (also known as a Type I error). (correct)\n\nQuestion: A statistical test that only examines effects in one direction, not both, is called‚Ä¶\nOptions:\n\nA one-headed test.\nA one-way street analysis.\nA wild goose chase.\nA one-tailed test.(correct)\n\nQuestion: TRUE or FALSE, in statistical testing, we always compare our test statistic against the same distribution.\nOptions:\n\nTRUE\nFALSE (correct)\n\nQuestion: You are running a study to test if the prevalence of a drug resistant mutation has changed over time. You will analyse your data using a z-test. The critical values for a two-tailed z-test at the significance level \\(\\alpha = 0.05\\) are at \\(\\pm1.96\\). You obtain a test statistic of -2.54. What should you do based on this result?\nOptions:\n\nReject the null hypothesis because the test statistic is less than zero.\nReject the null hypothesis because the test statistic exceeds the lower critical value. (correct)\nFail to reject the null hypothesis because the test statistic is negative.\nFail to reject the null hypothesis because the test statistic is less than the upper critical value.\n\nAnswer:. We should reject the null hypothesis because we exceed the critical values. In this example, we have two critical values, one negative value at -1.96 and one positive value at +1.96. Anything inside this region (greater than -1/96 but less than +1.96) is reasonably likely under the null hypothesis, but values outside this region are unlikely. Our value was outside this region, meaning we should reject the null hypothesis."
  },
  {
    "objectID": "tutorials/module3/activity3_power_static.html#testing-for-changes-in-drug-resistance-prevalence-over-time",
    "href": "tutorials/module3/activity3_power_static.html#testing-for-changes-in-drug-resistance-prevalence-over-time",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "Testing for changes in drug resistance prevalence over time",
    "text": "Testing for changes in drug resistance prevalence over time\nYou are concerned that the prevalence of antimalarial resistance might be increasing in your region. You have data on the prevalence of pfmdr1 N86Y mutations from a cross-sectional survey that took place three years ago. You plan to repeat the survey to establish if there has been a change in the prevalence of N86Y mutations over this time. The statistical test you plan to use is a z-test for proportions.\nQuestion: Which of these is the null hypothesis under this test?\nOptions:\n\nThe prevalence of pfmdr1 N86Y mutations has increased over the past three years.\nThe prevalence of pfmdr1 N86Y mutations has decreased over the past three years.\nThe prevalence of pfmdr1 N86Y mutations is the same now as it was three years ago. correct\nThe prevalence of pfmdr1 N86Y mutations differs between now and three years ago.\n\nThe study three years ago obtained genetic data from 80 samples, of which 12 were identified as carrying the N86Y mutation. We can estimate the prevalence as: \\[\np_1 = \\frac{12}{80} = 0.15\n\\] As part of our power analysis, we have to assume a known value of the prevalence at the present day. We will be pessimistic and assume that the prevalence has doubled over the three years to \\(p_2=0.30\\).\nWe know that the sample size was \\(n_1=80\\) for the first study. For the present study we plan to use a larger sample size of \\(n_2=300\\).\nGiven all of these values, we can calculate the expected value for our test statistic using the following formula: \\[\n\\mu_{\\text{alt}} = \\frac{|p_1 - p_2|}{\\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}}}\n\\] Note that the vertical lines around \\(|p_1 - p2|\\) mean we should take the absolute value of the difference in prevalence. This ensures that \\(\\mu_{\\text{alt}}\\) is always positive.\nComplete the following R code to calculate the value of \\(\\mu_{\\text{alt}}\\):\n\n# input parameters\np1 &lt;- 0.15\np2 &lt;- 0.3\nn1 &lt;- 80\nn2 &lt;- 300\n\n# calculate absolute value of difference in prevalence\np_diff &lt;- abs(p1 - p2)\n\n# calculate the standard error\nSE &lt;- sqrt(p1*(1 - p1) / n1 + p2*(1 - p2) / n2)\n\n# calculate mu_alt\nmu_alt &lt;- p_diff / SE\n\nprint(mu_alt)\n\n[1] 3.131975\n\n\nWe can use the value of \\(\\mu_{\\text{alt}}\\) to tell us our power. The formula for power under the z-test is:\n\\[\nP_{ow} = 1 - \\phi(z_{1-\\alpha/2} - \\mu_{\\text{alt}})\n\\]\nIn this formula, \\(\\phi(x)\\) refers to the area under the curve of a standard normal distribution from \\(-\\infty\\) up to the point \\(x\\). There is no simple way of calculating this value, but we can obtain it easily in R using the pnorm() function. As in previous activities, the value \\(z_{1 - \\alpha/2}\\) refers to the critical value of the normal distribution at a significance level \\(\\alpha\\) (two-tailed), which is approximately equal to 1.96.\nComplete the following R code to calculate the power under the planned study design:\n\n# define significance level and calculate z\nalpha &lt;- 0.05\nz &lt;- qnorm(1 - alpha / 2)\n\n# calculate power\npower &lt;- 1 - pnorm(z - mu_alt)\nprint(power)\n\n[1] 0.8794036\n\n\nFrom this calculation, we can see that our power is around 88%.\nQuestion: A power of 88% means‚Ä¶\nOptions:\n\nThere is an 88% chance that the study will be successful.\nThere is an 88% difference in prevalence between the time points.\nThere is an 88% chance that the alternative hypothesis is true.\nAssuming the alternative hypothesis is true, there is an 88% chance that we will correctly reject the null hypothesis. correct\n\nWe normally aim for 80% power, meaning this study design is adequately powered. In fact, we could argue that this study is slightly over-powered, meaning we could get away with using fewer samples and still be good enough.\nThe following power curve shows us the power as a function of the sample size (\\(n_2\\)). The region with 80% power or above is shaded in blue.\n\n\n\n\n\nQuestion: From this graph, what sample size is needed to achieve a power of 80%?\nOptions:\n\n140\n165 correct\n190\n285\n\nOnly 165 samples are needed for us to obtain 80% power. From the power curve, we can see that we reach diminishing returns as we continue increasing the sample size, meaning there is little benefit to continually driving up the sample size. The conclusion of our power analysis is that our initial plan to sequence 300 samples was excessive, and we can get away with sequencing far fewer samples. This is likely to lead to cost savings, and may allow us to redirect these resources elsewhere."
  },
  {
    "objectID": "tutorials/module3/activity3_power_static.html#detecting-rare-variants",
    "href": "tutorials/module3/activity3_power_static.html#detecting-rare-variants",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "Detecting rare variants",
    "text": "Detecting rare variants\nYou are planning a study to look for the presence of validated pfk13 mutations. You are not interested in estimating the prevalence of mutations, rather you want to know if any of these mutations are present in your population. You will test people for malaria as they present to a local health facility, and a subset of dried blood spots from malaria-positive patients will be sent away for sequencing. You only have the resources to sequence 100 samples, and you want to know if it is worth conducting a study with such a small sample size.\nThis type of presence-absence study can be framed as a hypothesis test. The null hypothesis is that there are no validated mutations present in the population, i.e.¬†the prevalence of these mutations is zero. Even a single observation of a mutation would disprove this null hypothesis, therefore - unlike most statistical tests (e.g.¬†the z-test above) - there is no test statistic to calculate here. Instead, we simply reject the null hypothesis if we see a single validated mutant, otherwise we fail to reject the null hypothesis.\nWe start by assuming a known prevalence, \\(p\\), for the validated mutations. We also need to define our sample size, \\(n\\). Samples are assumed to be drawn at random from the population.\nThe probability that a single sample is negative for mutants is \\(1-p\\). The probability that all \\(n\\) samples are negative is \\((1 - p)^n\\). The probability of seeing at least one mutant is one minus the probability of seeing no mutants. The probability of seeing at least one mutant is also defined as our power under this test, therefore:\n\\[\nP_{ow} = 1 - (1 - p)^n\n\\]\nComplete the following R code to calculate the power under an assumed prevalence of \\(p=0.05\\) and a sample size of \\(n=100\\):\n\n# define parameters\np &lt;- 0.05\nn &lt;- 100\n\n# calculate power\npower &lt;- 1 - (1 - p)^n\nprint(power)\n\n[1] 0.9940795\n\n\nWe have extremely high power under this example, which is reassuring.\nQuestion: What is the power if we assume the prevalence of validated mutants is only 1% in the population?\nOptions:\n\n51%\n63% correct\n76%\n84%\n\nThe following power curves show power as a function of sample size for a range of different value of \\(p\\):\n\n\n\n\n\nQuestion: From these power curves, what sample size is needed to achieve 80% power if we assume the true prevalence of mutants in the population is 2%?\nOptions:\n\n40\n60\n80 correct\n90\n\nQuestion: What about if we assume the prevalence is 1%?\nOptions:\n\n16\n32\n80\nMore than 100, meaning we cannot achieve 80% power within our resource limits.correct\n\nOur original question was whether it was worth conducting this study given our tight resource constraints of at most 100 samples sequenced. What the graph shows us is that whether or not it is worth running this study depends on what we are happy to assume about the prevalence of mutations in the population. If we are very worried about missing mutations present at only 1% in the population, then it is not worth running this study (unless we have some other indirect benefits of the sequencing) as we will be under-powered. On the other hand, if we would not be very concerned about mutations at 1% prevalence, and we are much more concerned about them reaching 5% prevalence or higher, then we would achieve adequate power with as few as 32 samples. This is the point at which statistical information needs to be combined with clinical and programmatic information to make an informed decision about the most appropriate course of action."
  },
  {
    "objectID": "tutorials/module3/activity3_power_static.html#bonus-questions",
    "href": "tutorials/module3/activity3_power_static.html#bonus-questions",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "Bonus questions",
    "text": "Bonus questions\nA study was conducted with the aim of detecting rare pfk13 variants. A sample size of 32 was used, as this was determined to be sufficient based on statistical arguments. However, during sequencing it also became clear that pfmdr1 mutations could be sequenced from the same samples at little extra cost. 10 out of the 32 samples were found to carry the pfmdr1 N86Y mutation, giving a prevalence of 32%. This was surprising - only last year a study had found a prevalence of 20% in a sample of 150 people. This raised the question of whether the prevalence of N86Y mutations had increased significantly over this period.\nThe research team carried out a z-test for proportions to see if there was a statistically significant increase between the two studies. Here are the inputs to their test:\n\\[\n\\begin{align}\n\\hat{p}_1 &= \\frac{30}{150} = 0.20 \\\\\n\\hat{p}_2 &= \\frac{10}{32} = 0.31 \\\\\n\\hat{p} &= \\frac{30 + 10}{150 + 32} = 0.22 \\\\\nn_1 &= 150 \\\\\nn_2 &= 32\n\\end{align}\n\\] The test statistic was calculated from these values as follows: \\[\nZ = \\frac{|\\hat{p}_1 - \\hat{p}_2|}{\\sqrt{\\hat{p}(1 - \\hat{p})\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n\\]\nThis gives the value \\(Z = 1.40\\). The researchers compared this value against the critical values of \\(\\pm1.96\\) and found that this was non-significant. Therefore, they did not have evidence to reject the null hypothesis that prevalence stayed the same over this time period. They took this as reassurance that prevalence of N86Y mutations is not increasing in the region.\nHowever‚Ä¶\nQuestion: Were they right to come to this conclusion? What was their power to detect a a change in prevalence from 20% to 30%? What about a change from 20% to 40%? How does this ‚Äúretrospective‚Äù power analysis change how we interpret the non-significant finding from the z-test?\nAnswer:\nWhen we conduct power analysis under the z-test, we find that power to detect a change from 20% to 30% was only around 21%. Similarly, power to detect a change from 20% to 40% was still only 58%. This falls well below the usual 80% power threshold. With this low power there would be a very good chance of getting a non-significant result even if prevalence had doubled!\nThe problem here is that the sample size of 32 is too small, leading to an underpowered study. This happened because the study design was not powered to answer questions about the change in prevalence of N86Y mutations, rather it was designed and powered to answer a question about presence/absence of rare pfk13 variants.\nThe lack of power means we shouldn‚Äôt read too much into the non-significant finding. There could have been major changes in the prevalence of N86Y mutations over the year, but we would have very little chance of rejecting the null hypothesis due to our lack of power.\nQuestion: How could this low power have been avoided?\nAnswer: If our plan was to look for changes in prevalence of N86Y mutations alongside looking for rare pfk13 mutants then this should have been accounted for at the design stage. A power analysis should have been conducted that took into account both endpoints. This would have resulted in a larger sample size that was sufficient to answer both questions."
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_static.html",
    "href": "tutorials/module4/activity4_multicluster_static.html",
    "title": "Activity 4: Intra-cluster correlation",
    "section": "",
    "text": "This activity focuses on measuring over-dispersion in multi-cluster studies using the example of a hypothetical pfhrp2/3 deletion study in Tanzania. In this activity you will learn:\n\nWhat over-dispersion looks like in prevalence data, and how to detect it statistically\nHow to measure over-dispersion using different metrics\nThe impact of over-dispersion on statistical efficiency\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is simulated for teaching purposes only. It does not necessarily represent the real epidemiological situation."
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_static.html#learning-outcomes",
    "href": "tutorials/module4/activity4_multicluster_static.html#learning-outcomes",
    "title": "Activity 4: Intra-cluster correlation",
    "section": "",
    "text": "This activity focuses on measuring over-dispersion in multi-cluster studies using the example of a hypothetical pfhrp2/3 deletion study in Tanzania. In this activity you will learn:\n\nWhat over-dispersion looks like in prevalence data, and how to detect it statistically\nHow to measure over-dispersion using different metrics\nThe impact of over-dispersion on statistical efficiency\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is simulated for teaching purposes only. It does not necessarily represent the real epidemiological situation."
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_static.html#analyzing-data-from-a-multi-cluster-pfhrp2-deletion-study",
    "href": "tutorials/module4/activity4_multicluster_static.html#analyzing-data-from-a-multi-cluster-pfhrp2-deletion-study",
    "title": "Activity 4: Intra-cluster correlation",
    "section": "Analyzing data from a multi-cluster pfhrp2 deletion study",
    "text": "Analyzing data from a multi-cluster pfhrp2 deletion study\n\nBackground\nYou are collaborating with the Tanzanian National Malaria Control Programme (NMCP) to investigate the prevalence of pfhrp2/3 gene deletions in the Dodoma region of Tanzania. These gene deletions pose a significant threat to malaria control efforts as they can lead to parasites being undetectable by rapid diagnostic tests (RDTs) that rely exclusively on the HRP2 protein. Undetected cases may lead to delays in treatment or missed malaria diagnoses, undermining effective case management.\nA multi-cluster study has been performed in 8 sites within the Dodoma region of Tanzania. The results of this study are shown below:\n\n\n\n\n\n\n\n\n\n\n\nSite\nConfirmed Malaria\n(n)\npfhrp2 Deleted\n(x)\npfhrp2 Deletion Prevalence\n(p)\n\n\n\n\nChalinze\n100\n7\n0.070\n\n\nIbwaga\n80\n12\n0.150\n\n\nLukali\n100\n7\n0.070\n\n\nMalolo\n100\n26\n0.260\n\n\nMafene\n95\n25\n0.263\n\n\nMpendo\n100\n45\n0.450\n\n\nNhinhi\n50\n0\n0.000\n\n\nRudi\n100\n11\n0.110\n\n\n\n\nTable 1: pfhrp2 deletion data by Site\n\n\n\n\n\n\n\n\n\n\n\nThe columns of this table are available in R as the variables n, x and p.\n\n\nEstimating the global prevalence\nWe want to use the information over all 8 sites to estimate the prevalence of pfhrp2 deletions in the Dodoma region as a whole. One way to do this is to take the mean over sites:\n\nmean(p)\n\n[1] 0.171625\n\n\nThe mean prevalence is around 17%. However, this calculation ignores differences in sample sizes between sites. For example, the Nhinhi site is given just as much weight as the Rudi site, despite having half the number of confirmed malaria cases. A different approach is to use a weighted average, where the weights are given by the sample sizes:\n\n# define weights based on sample size\nweights &lt;- n\n\n# calculate prevalence as a weighted average over sites\nsum(weights * p) / sum(weights)\n\n[1] 0.1834276\n\n\nWe now find that prevalence is closer to 18%. In this example, there is not much difference between the two methods, but in general they can give quite different results. Neither approach is more correct than the other, they just have different strengths and weaknesses. The unweighted mean is more conservative when there could be large intra-cluster correlation. On the other hand, the weighted mean avoids the issue of small clusters having a large influence on the final estimate.\nFor the purposes of this tutorial, we will use the unweighted mean as our estimate over all sites. This value is often called the ‚Äúglobal‚Äù prevalence, and is given the symbol \\(\\hat{p}\\).\n\np_global &lt;- mean(p)\n\n\n\nDetecting over-dispersion\nNow that we have an estimate of the global prevalence, we can look for over-dispersion in the data. If all patients enrolled in the study have the same probability \\(\\hat{p}\\) of carrying the pfhrp2 deletion, then we expect to see a certain level of variation between sites. Most of the time, the site-level prevalence should be within the following 95% interval: \\[\n\\hat{p} \\pm z_{1 - \\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n_i}}\n\\] where \\(n_i\\) is the sample size in the \\(i^{\\text{th}}\\) site. Because this is a 95% interval, we should expect sites to fall within this range 95% of the time. For our study involving 8 sites, it would be very unusual to see more than one site with a prevalence outside this range.\nThe plot below shows the site-level prevalence in red. The global mean prevalence of 17% shown as a horizontal dashed line and the 95% interval shown as an error bar.\n\n\n\n\n\nQuestion: How many sites have a prevalence outside the expected 95% interval?\nOptions:\n\n0\n2\n4\n6 (correct)\n\nQuestion: From this plot, does the prevalence appear to be over-dispersed, under-dispersed, or neither?\nOptions:\n\nOver-dispersed (correct)\nUnder-dispersed\nNeither\n\nQuestion: What could cause this over-dispersion?\nOptions:\n\nLimited migration and gene flow between sites.\nVariation in treatment practices leading to different selective pressures between sites.\nLocal outbreaks within sites, driven by infected individuals carrying pfhrp2 deletions.\nAll of the above (correct)\n\nQuestion: Why does the Nhinhi site have a slightly wider 95% interval than the other sites?\nOptions:\n\nThe Nhinhi site has higher prevalence of pfhrp2 deletions.\nThe diagnostic methods used at the Nhinhi site are less accurate.\nThe Nhinhi site is geographically isolated.\nThe sample size in Nhinhi is lower than other sites (correct)"
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_static.html#measuring-the-impact-of-over-dispersion",
    "href": "tutorials/module4/activity4_multicluster_static.html#measuring-the-impact-of-over-dispersion",
    "title": "Activity 4: Intra-cluster correlation",
    "section": "Measuring the impact of over-dispersion",
    "text": "Measuring the impact of over-dispersion\n\nThe design effect\nOne way of quantifying the effect of over-dispersion is through the design effect (\\(D_{\\text{eff}}\\)). We can estimate the design effect by calculating the observed variance between sites and dividing this by the variance that we would expect to see under simple random sampling (SRS), which is when all individuals in the study are perfectly independent.\nThe observed variance between sites can be calculated as:\n\\[\ns^2 = \\frac{1}{c-1}\\sum_{i=1}^c (\\hat{p}_i - \\hat{p})^2\n\\] where \\(c\\) is the number of sites (8 in our case) and \\(\\hat{p}_i\\) is the prevalence in site \\(i\\). This formula is called the sample variance, and it is found in many areas of statistics. We don‚Äôt need to calculate this value by hand, instead we can do it very easily in R using the var() function:\n\n# calculate observed variance between sites\nvar_observed &lt;- var(p)\nprint(var_observed)\n\n[1] 0.02114684\n\n\nNext, we need to calculate the variance that we would expect to see under simple random sampling (SRS). This is given by:\n\\[\n\\text{var}_{\\text{SRS}} = \\frac{1}{c} \\sum_{i=1}^c \\frac{\\hat{p}(1 - \\hat{p})}{n_i}\n\\] We can calculate this in R as follows:\n\nvar_SRS &lt;- mean(p_global*(1 - p_global) / n)\nprint(var_SRS)\n\n[1] 0.001653192\n\n\nOur observed variance was 0.0211, but the variance we would expect to see under SRS is only 0.00165. This tells us that our data are more variable than we would expect by chance, in other words this confirms that there is over-dispersion in our data. We calculate the design effect as the ratio of these two quantities:\n\nDeff &lt;- var_observed / var_SRS\nprint(Deff)\n\n[1] 12.79152\n\n\nWe obtain a design effect of \\(D_{\\text{eff}}=12.79\\).\nQuestion: The design effect measures:\nOptions:\n\nHow good a study is.\nThe statistical inefficiency of a study, relative to SRS. (correct)\nThe number of sites used in a study.\nThe average prevalence across sites.\n\nThe design effect is a measure of the statistical inefficiency of a study design. Larger values indicate less efficient designs, with a value of \\(D_{\\text{eff}}=1\\) representing a gold standard in terms of statistical efficiency. Our observed value of \\(D_{\\text{eff}}=12.79\\) indicates that our study has a high level of statistical inefficiency due to the high level of over-dispersion in the data.\nQuestion: A high value of the design effect means we can expect to see:\nOptions:\n\nGreater uncertainty around our global estimate of the prevalence \\(\\hat{p}\\).\nLower power.\nLarger sample sizes needed.\nAll of the above. (correct)\n\n\n\nThe effective sample size\nAnother way to quantify the impact of over-dispersion is through the effective sample size, \\(N_{\\text{eff}}\\). The effective sample size tells us how many perfectly independent samples we would need in order to achieve the same level of statistical efficiency. In other words, it tells us how large our study would need to be if we could get rid of over-dispersion completely. We calculate \\(N_{\\text{eff}}\\) by dividing the true total sample size by the design effect:\n\\[\nN_{\\text{eff}} = \\frac{\\sum_{i=1}^c n_i}{D_{\\text{eff}}}\n\\] Here is R code that performs this calculation:\n\nsum(n) / Deff\n\n[1] 56.67818\n\n\nOur effective sample size is just 56.7, even though our total sample size was 725! Amazingly, this means that, due to correlations within sites, it‚Äôs as if we had enrolled only 56 patients! This emphasizes the importance of considering over-dispersion. If we ignored over-dispersion in our analysis then we might kid ourselves into thinking we had a large amount of data and hence very precise estimates of the regional prevalence. When we deal with it correctly we get much more robust results.\n\n\nThe intra-cluster correlation coefficient\nThe third and final measure that we will consider is the intra-cluster correlation coefficient (ICC), often given the symbol \\(\\rho\\). This is a measure between 0 and 1 that describes how correlated observations are within a cluster (site). The relationship between the ICC and the design effect is:\n\\[\nD_{\\text{eff}} = 1 + \\rho(\\bar{n} - 1)\n\\] where \\(\\bar{n}\\) is the mean sample size over sites. Notice that when there is zero intra-cluster correlation (\\(\\rho=0\\)) the design effect equals 1, indicating that we are highly statistically efficient. The larger the value of \\(\\rho\\), the higher \\(D_{\\text{eff}}\\) gets and the more inefficient our design.\nWe can flip this equation around to give us the ICC as a function of the design effect:\n\\[\n\\rho = \\frac{D_{\\text{eff}} - 1}{\\bar{n} - 1}\n\\]\nComplete the following R code to calculate the value of the ICC from the design effect:\n\nn_mean &lt;- mean(n)\n\n(Deff - 1) / (n_mean - 1)\n\n[1] 0.1315651\n\n\nBut why did we bother working out the ICC? What advantage does this measure have over other measures like the design effect? To answer this, consider the following question:\nQuestion: Another study run in Kenya with a much larger sample size also found a design effect of \\(D_{\\text{eff}} = 12.79\\). Does this mean the two countries have similar levels of intra-cluster correlation?\nOptions:\n\nYes, the design effect is the same so the ICC must also be the same.\nNo, the design effect depends on the same size and so we cannot make this comparison. (correct)\n\nThe same value of \\(\\rho\\) can give very different values of \\(D_{\\text{eff}}\\), depending on the sample size \\(\\bar{n}\\). For this reason, we should be very careful when comparing the design effect between studies. Just because one study found a small design effect, does not mean that we can also assume the same small value when designing a new study. On the other hand, the ICC does not depend on the sample size and so tends to be more useful when comparing between studies."
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_static.html#bonus-questions",
    "href": "tutorials/module4/activity4_multicluster_static.html#bonus-questions",
    "title": "Activity 4: Intra-cluster correlation",
    "section": "Bonus questions",
    "text": "Bonus questions\nIn an earlier module, you learned how to calculate a confidence interval (CI) on a prevalence estimate using the Wald interval. Use the information in Table 1 to calculate a 95% CI around our global prevalence estimate. For the sample size, use the total sample size summed over all clusters. This is equivalent to assuming that all observations are completely independent. What do you get for the margin of error, and the lower and upper limits of your 95% CI?\nNow repeat this analysis, but instead of using the total sample size, use the effective sample size that you calculated above. This analysis does not assume that all observations are independent, and instead takes account of over-dispersion. What do you get for the margin of error, and the lower and upper limits of your 95% CI? How does this compare with your previous answer?"
  },
  {
    "objectID": "tutorials/module_sample_size.html",
    "href": "tutorials/module_sample_size.html",
    "title": "Module 5: Sample size calculation",
    "section": "",
    "text": "Welcome to Module 5: Sample size calculation.\nIn this module, we‚Äôll focus on how to determine the appropriate sample size for your study based on desired power and hypothesis testing parameters. This module will enhance your ability to design studies that are adequately powered to detect meaningful effects.\n\n\nBy the end of this tutorial, you will be able to:\n\nDerive the equation for calculating sample size interactively.\nUnderstand how power relates to sample size calculation.\nInterpret power curves and sample size tables.\nDesign sample sizes based on specific hypotheses."
  },
  {
    "objectID": "tutorials/module_sample_size.html#introduction",
    "href": "tutorials/module_sample_size.html#introduction",
    "title": "Module 5: Sample size calculation",
    "section": "",
    "text": "Welcome to Module 5: Sample size calculation.\nIn this module, we‚Äôll focus on how to determine the appropriate sample size for your study based on desired power and hypothesis testing parameters. This module will enhance your ability to design studies that are adequately powered to detect meaningful effects.\n\n\nBy the end of this tutorial, you will be able to:\n\nDerive the equation for calculating sample size interactively.\nUnderstand how power relates to sample size calculation.\nInterpret power curves and sample size tables.\nDesign sample sizes based on specific hypotheses."
  },
  {
    "objectID": "tutorials/module_sample_size.html#deriving-the-sample-size-formula",
    "href": "tutorials/module_sample_size.html#deriving-the-sample-size-formula",
    "title": "Module 5: Sample size calculation",
    "section": "Deriving the sample size formula",
    "text": "Deriving the sample size formula\nIn this section, we‚Äôll interactively derive the equation for calculating the sample size required for a study, focusing on the specific hypothesis:\n\nNull hypothesis (H0): p1=p2\nAlternative hypothesis (H1): p1 = p2 + 10%\n\nThis means we‚Äôre interested in detecting a difference of 10 percentage points between two proportions. For example, if we are comparing the prevalence of a drug resistance mutation between two time points, we want to know whether the prevalence remained the same or increased by 10%.\nIMAGE OF SS FORMULA\n\nUnderstanding the components\nBefore we derive the equation, let‚Äôs understand the key components involved in sample size calculation:\n\nEffect size (Œî): The minimum difference between groups that you want to detect.\nSignificance Level (Œ±): The probability of making a Type I error (commonly set at 0.05).\nPower (1 - Œ≤): The probability of correctly rejecting a false null hypothesis (commonly desired at 80% or 0.80).\nStandard deviation (œÉ): A measure of variability in the data.\n\n\n\nDeriving the formula\nWe want to determine the sample size needed to detect a difference in proportions between two groups, where the difference is 10%.\nNow we are going to derive this formula step-by-step to determine this sample size.\nFirst we define our effect size delta:\n\ndelta &lt;- 10"
  },
  {
    "objectID": "tutorials/module_sample_size.html#bonus",
    "href": "tutorials/module_sample_size.html#bonus",
    "title": "Module 5: Sample size calculation",
    "section": "Bonus",
    "text": "Bonus\n\nopen from code (do it yourself with hints), repeat for sample size of eg 500"
  },
  {
    "objectID": "tutorials/module_sample_size.html#resources",
    "href": "tutorials/module_sample_size.html#resources",
    "title": "Module 5: Sample size calculation",
    "section": "Resources",
    "text": "Resources"
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "All of the materials from this workshop are freely available. We suggest you work through them in order (see the Schedule for the order in which materials were presented at the pre-ASTMH workshop)."
  },
  {
    "objectID": "lectures.html#list-of-all-the-lectures-pdfs",
    "href": "lectures.html#list-of-all-the-lectures-pdfs",
    "title": "Lectures",
    "section": "List of all the lectures (PDFs)",
    "text": "List of all the lectures (PDFs)"
  },
  {
    "objectID": "index.html#workshop-format",
    "href": "index.html#workshop-format",
    "title": "Malaria Molecular Surveillance Study Design workshop",
    "section": "Workshop format",
    "text": "Workshop format\nOver the course of 1.5 days (see Schedule) we will have a combination of lectures, hands-on exercises, and group discussions. The workshop will be in English. We will cover several topics relevant to malaria molecular surveillance (MMS) study design, including:\n\nStatistical power\nSample size calculation\nEstimating prevalence\nMeasuring changes in prevalence\nCluster-based study design and intra-cluster correlation\nGuest lectures from experts conducting MMS studies"
  },
  {
    "objectID": "index.html#materials",
    "href": "index.html#materials",
    "title": "Malaria Molecular Surveillance Study Design workshop",
    "section": "Materials",
    "text": "Materials\nAll of the materials were developed by Bob Verity and Shazia Ruybal-Pes√°ntez and are freely available under the MIT license. This website is produced from a Github repository."
  },
  {
    "objectID": "index.html#acknowledgments-and-funding",
    "href": "index.html#acknowledgments-and-funding",
    "title": "Malaria Molecular Surveillance Study Design workshop",
    "section": "Acknowledgments and funding",
    "text": "Acknowledgments and funding\nFunding for this workshop was provided by the Gates Foundation."
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "All of the materials from this workshop are freely available. We suggest you work through them in order (see the Schedule for the order in which materials were presented at the pre-ASTMH workshop)."
  },
  {
    "objectID": "tutorials.html#list-of-all-the-tutorials",
    "href": "tutorials.html#list-of-all-the-tutorials",
    "title": "Tutorials",
    "section": "List of all the tutorials",
    "text": "List of all the tutorials\n\nModule 1: Sampling from a population\nModule 2:Sample size based on precision\nModule 3\nModule 4\nModule 5\nModule 5\nModule 6: Designing a study for multiple end-points"
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_interactive.html",
    "href": "tutorials/module4/activity4_multicluster_interactive.html",
    "title": "Activity 4: Dealing with over-dispersion in multi-cluster studies",
    "section": "",
    "text": "Welcome to Activity 4: Dealing with over-dispersion in multi-cluster studies\nIn this activity, we will consider some of the features of multi-cluster studies that separate them from single-cluster studies. Very often in malaria surveillance we want to pool information over multiple sites. These could be health facilities, towns, or even regions of a country. By combining information over sites we can estimate the average value of some quantity of interest - for example the prevalence of a drug resistance mutation - without being too highly influenced by local variations. However, when pooling results, care must be taken not to overstate the amount of information we have. This is particularly true if data are over-dispersed, meaning there is more variation between sites than expected. In this case, our sample size is effectively diminished and in some cases power can be badly affected.\n\n\nBy the end of this tutorial, you will be able to:\n\nDetect over-dispersion\nQuantify over-dispersion using metrics including the design effect, effective sample size, and intra-cluster correlation coefficient\nUnderstand the impact of over-dispersion on statistical efficiency\nConstruct confidence intervals and perform hypothesis tests while accounting for over-dispersion\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is artificial and designed for teaching purposes only. It does not necessarily represent the real epidemiological situation in these locations."
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_interactive.html#introduction",
    "href": "tutorials/module4/activity4_multicluster_interactive.html#introduction",
    "title": "Activity 4: Dealing with over-dispersion in multi-cluster studies",
    "section": "",
    "text": "Welcome to Activity 4: Dealing with over-dispersion in multi-cluster studies\nIn this activity, we will consider some of the features of multi-cluster studies that separate them from single-cluster studies. Very often in malaria surveillance we want to pool information over multiple sites. These could be health facilities, towns, or even regions of a country. By combining information over sites we can estimate the average value of some quantity of interest - for example the prevalence of a drug resistance mutation - without being too highly influenced by local variations. However, when pooling results, care must be taken not to overstate the amount of information we have. This is particularly true if data are over-dispersed, meaning there is more variation between sites than expected. In this case, our sample size is effectively diminished and in some cases power can be badly affected.\n\n\nBy the end of this tutorial, you will be able to:\n\nDetect over-dispersion\nQuantify over-dispersion using metrics including the design effect, effective sample size, and intra-cluster correlation coefficient\nUnderstand the impact of over-dispersion on statistical efficiency\nConstruct confidence intervals and perform hypothesis tests while accounting for over-dispersion\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is artificial and designed for teaching purposes only. It does not necessarily represent the real epidemiological situation in these locations."
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_interactive.html#analyzing-data-from-a-multi-cluster-pfhrp2-deletion-study",
    "href": "tutorials/module4/activity4_multicluster_interactive.html#analyzing-data-from-a-multi-cluster-pfhrp2-deletion-study",
    "title": "Activity 4: Dealing with over-dispersion in multi-cluster studies",
    "section": "Analyzing data from a multi-cluster pfhrp2 deletion study",
    "text": "Analyzing data from a multi-cluster pfhrp2 deletion study\n\nBackground\nYou are collaborating with the Tanzanian National Malaria Control Programme (NMCP) to investigate the prevalence of pfhrp2/3 gene deletions in the Dodoma region of Tanzania. These gene deletions pose a significant threat to malaria control efforts as they can lead to parasites being undetectable by rapid diagnostic tests (RDTs) that rely exclusively on the HRP2 protein. Undetected cases may lead to delays in treatment or missed malaria diagnoses, undermining effective case management.\nA multi-cluster study has been performed in 8 sites within the Dodoma region. The results of this study are shown below:\n\n\n\n\n\n\n\n\n\n\n\nSite\nConfirmed Malaria\n(n)\npfhrp2 Deleted\n(x)\npfhrp2 Deletion Prevalence\n(p)\n\n\n\n\nChalinze\n100\n7\n0.070\n\n\nIbwaga\n80\n12\n0.150\n\n\nLukali\n100\n7\n0.070\n\n\nMalolo\n100\n26\n0.260\n\n\nMafene\n95\n25\n0.263\n\n\nMpendo\n100\n45\n0.450\n\n\nNhinhi\n50\n0\n0.000\n\n\nRudi\n100\n11\n0.110\n\n\n\n\nTable 1: pfhrp2 deletion data broken down by site\n\n\n\n\n\n\n\n\n\n\n\nIn the R chunks below, you will be able to access these columns through the variables n, x, and p, as shown here:\n\n\n# you can access the following vectors\nn\nx\np\n\n\n\n\n\nEstimating the global prevalence\nWe want to use the information over all 8 sites to estimate the prevalence of pfhrp2 deletions in the Dodoma region as a whole. This is often called the ‚Äúglobal‚Äù prevalence estimate. We will use \\(\\hat{p}\\) to denote the global prevalence, and \\(\\hat{p}_i\\) to denote the site-level prevalence in the \\(i^\\text{th}\\) site.\nA common way to calculate \\(\\hat{p}\\) is to take the mean over sites.\n\\[\n\\hat{p} = \\frac{1}{c} \\sum_{i=1}^c \\hat{p}_i\n\\]\nwhere there are \\(c\\) sites, so in our case \\(c = 8\\).\nComplete the following R code to calculate p_global as the mean prevalence over sites. The values in Table 1 are available through the variables n, x and p.\n\n\n# calculate p_global as mean prevalence over sites\np_global &lt;- \n\nprint(p_global)\n\n\n\n\n\n# calculate p_global as mean prevalence over sites\np_global &lt;- mean(p)\n\nprint(p_global)\n\n\n\n\nClick to see the answer\n\nYou should find that \\(\\hat{p} = 0.172\\), or 17.2% prevalence.\n\n\nThis calculation ignores differences in sample sizes between sites. For example, the Nhinhi site is given just as much weight as the Rudi site, despite having half the number of confirmed malaria cases. A different approach is to calculate \\(\\hat{p}\\) as the weighted average of the site-level prevalence, where the weights are given by the sample sizes. This is mathematically equivalent to summing the numerator and the denominators separately before dividing:\n\\[\n\\hat{p} = \\frac{\\sum_{i=1}^c x_i}{\\sum_{i=1}^c n_i}\n\\]\nComplete the following R code to calculate p_global as the weighted mean prevalence over sites:\n\n\n# calculate p_global as weighted mean prevalence over sites\np_global &lt;- \n\nprint(p_global)\n\n\n\n\n\n# calculate p_global as weighted mean prevalence over sites\np_global &lt;- sum(x) / sum(n)\n\nprint(p_global)\n\n\n\n\nClick to see the answer\n\nYou should find that \\(\\hat{p} = 0.183\\), or 18.3% prevalence.\n\n\nIn this example, prevalence is slightly higher via the weighted mean than the ordinary mean. Neither approach is more correct than the other, rather they have different strengths and weaknesses. The unweighted mean treats each site as a single observation, which is a robust approach when there is the possibility of over-dispersion. On the other hand, the weighted mean avoids small clusters having a large influence on the final estimate. For the purposes of this activity, we will use the unweighted mean as our global estimate.\n\n\nDetecting over-dispersion\nNow that we have an estimate of the global prevalence, we can look for over-dispersion in the data. If all patients enrolled in the study were completely independent, meaning they all had the same probability \\(\\hat{p}\\) of carrying the pfhrp2 deletion, then we would expect to see a certain level of variation between sites. Most of the time, the site-level prevalence should be within the following 95% interval: \\[\n\\hat{p} \\pm z_{1 - \\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n_i}}\n\\] where \\(n_i\\) is the sample size in the \\(i^{\\text{th}}\\) site. Because this is a 95% interval, we should expect sites to fall within this range around 95% of the time. For our study involving 8 sites, we may see one site-level prevalence outside this range by chance, but it would be very unusual to see more than one outside this range.\nThe plot below shows the site-level prevalence in red. The global mean prevalence of 17.2% is shown as a horizontal dashed line, and the 95% interval is shown as an error bar."
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_interactive.html#quantifying-over-dispersion",
    "href": "tutorials/module4/activity4_multicluster_interactive.html#quantifying-over-dispersion",
    "title": "Activity 4: Dealing with over-dispersion in multi-cluster studies",
    "section": "Quantifying over-dispersion",
    "text": "Quantifying over-dispersion\n\nThe design effect\nOne way of quantifying the effect of over-dispersion is through the design effect, denoted \\(D_{\\text{eff}}\\). We can estimate the design effect by calculating the observed variance between sites and dividing this by the variance that we would expect under simple random sampling (SRS). If the data are over-dispersed then the observed variance will be greater than the expected variance, meaning \\(D_{\\text{eff}}\\) will be greater than 1.\nThe observed variance between sites can be calculated as:\n\\[\n\\text{Var}_{\\text{obs}} = \\frac{1}{c-1}\\sum_{i=1}^c (\\hat{p}_i - \\hat{p})^2\n\\]\nThis formula is called the sample variance, it is found in many areas of statistics. We don‚Äôt need to calculate this value by hand, instead we can do it very easily in R using the var() function:\n\n# calculate observed variance between sites\nvar_observed &lt;- var(p)\n\nprint(var_observed)\n\n[1] 0.02114684\n\n\nNext, we need to calculate the variance that we would expect to see under simple random sampling (SRS). This is given by:\n\\[\n\\text{Var}_{\\text{SRS}} = \\frac{1}{c} \\sum_{i=1}^c \\frac{\\hat{p}(1 - \\hat{p})}{n_i}\n\\] We can calculate this in R as follows:\n\n# calculate expected variance under SRS\nvar_SRS &lt;- mean(p_global*(1 - p_global) / n)\n\nprint(var_SRS)\n\n[1] 0.001653192\n\n\nWe calculate the design effect as the ratio of these two quantities: \\[\nD_{\\text{eff}} = \\frac{\\text{Var}_{\\text{obs}}}{\\text{Var}_{\\text{SRS}}}\n\\] Complete the following R code to calculate the design effect:\n\n\n# calculate design effect from the variances\nDeff &lt;- \n\nprint(Deff)\n\n\n\n\n\n# calculate design effect from the variances\nDeff &lt;- var_observed / var_SRS\n\nprint(Deff)\n\n\n\n\nClick to see the answer\n\nYou should find that \\(D_{\\text{eff}} = 12.79\\).\n\n\nThe design effect is a measure of the statistical inefficiency of a study design. Larger values indicate less efficient designs, with a value of \\(D_{\\text{eff}}=1\\) representing a gold standard in terms of statistical efficiency. Our observed value of \\(D_{\\text{eff}}=12.79\\) indicates that our study has a high level of statistical inefficiency due to the over-dispersion in the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe effective sample size\nAnother way to quantify the impact of over-dispersion is through the effective sample size, \\(N_{\\text{eff}}\\). The effective sample size tells us how many perfectly independent samples we would need in order to achieve the same level of statistical efficiency. In other words, it tells us how large our study would need to be if we could get rid of over-dispersion completely. We calculate \\(N_{\\text{eff}}\\) by dividing the true total sample size by the design effect:\n\\[\nN_{\\text{eff}} = \\frac{\\sum_{i=1}^c n_i}{D_{\\text{eff}}}\n\\]\nComplete the following R code to calculate an effective sample size:\n\n\n# calculate effective sample size based on total sample size and design effect\nNeff &lt;- \n\nprint(Neff)\n\n\n\n\n\n# calculate effective sample size based on total sample size and design effect\nNeff &lt;- sum(n) / Deff\n\nprint(Neff)\n\n\n\n\nClick to see the answer\n\nYou should find that \\(N_{\\text{eff}} = 56.7\\).\n\n\nOur effective sample size is just 56.7, even though our total sample size was 725. Amazingly, this means that - from the point of view of estimating prevalence - it‚Äôs as though we had enrolled only 56 patients! The high correlation within sites meant that we were effectively sampling the same ‚Äúsort‚Äù of individual over and over again. We may have been better off recruiting more sites rather than sampling deeply within a site to avoid this issue.\n\n\nThe intra-cluster correlation coefficient\nThe third and final measure that we will consider is the intra-cluster correlation coefficient (ICC), denoted \\(r\\). This is a measure between 0 and 1 that describes how correlated observations are within a cluster (site). If there is correlation with clusters then there must be over-dispersion in the data, and likewise if data are over-dispersed then there must be intra-cluster correlation greater than 0.\nThe relationship between the ICC and the design effect is:\n\\[\nD_{\\text{eff}} = 1 + r(\\bar{n} - 1)\n\\] where \\(\\bar{n}\\) is the mean sample size over sites. Notice that when \\(r\\) is zero the design effect equals 1, indicating that we are as statistically efficient as under simple random sampling. The larger the value of \\(r\\), the higher the design effect and the more inefficient our design.\nWe can flip this equation around to give us the ICC as a function of the design effect:\n\\[\nr = \\frac{D_{\\text{eff}} - 1}{\\bar{n} - 1}\n\\]\nComplete the following R code to calculate the value of the ICC from the design effect that we estimated above:\n\n\n# calculate the mean sample size\nn_bar &lt;- \n\n# calculate the ICC\nICC &lt;- \n\nprint(ICC)\n\n\n\n\n\n# calculate the mean sample size\nn_bar &lt;- mean(n)\n\n# calculate the ICC\nICC &lt;- (Deff - 1) / (n_bar - 1)\n\nprint(ICC)\n\n\n\n\nClick to see the answer\n\nYou should find that \\(r = 0.132\\).\n\n\nThe ICC can be harder to interpret than other measures like the design effect or effective sample size, but it does have certain advantages. We can think of the ICC as an intrinsic property of the population, while the design effect is only a measure of the inefficiency of our study. While \\(D_{\\text{eff}}\\) is influenced by \\(r\\), it is also influenced by many other factors, most notably the sample size. If we were to double the sample size of a study then our design effect would change, but the ICC would stay exactly the same. This makes it straightforward to compare values of \\(r\\) between studies, while we have to take great care when comparing values of \\(D_{\\text{eff}}\\)."
  },
  {
    "objectID": "tutorials/module4/activity4_multicluster_interactive.html#accounting-for-over-dispersion",
    "href": "tutorials/module4/activity4_multicluster_interactive.html#accounting-for-over-dispersion",
    "title": "Activity 4: Dealing with over-dispersion in multi-cluster studies",
    "section": "Accounting for over-dispersion",
    "text": "Accounting for over-dispersion\nWe have seen what over-dispersion looks like in prevalence data, and how it can be quantified. Now we will learn how to incorporate over-dispersion into our design and analysis phases so we can be robust to its effects.\n\nOver-dispersion and confidence intervals\nLet‚Äôs look again at the pfhrp2/3 data from Dodoma region:\n\n\n\n\n\n\n\n\n\n\n\nSite\nConfirmed Malaria\n(n)\npfhrp2 Deleted\n(x)\npfhrp2 Deletion Prevalence\n(p)\n\n\n\n\nChalinze\n100\n7\n0.070\n\n\nIbwaga\n80\n12\n0.150\n\n\nLukali\n100\n7\n0.070\n\n\nMalolo\n100\n26\n0.260\n\n\nMafene\n95\n25\n0.263\n\n\nMpendo\n100\n45\n0.450\n\n\nNhinhi\n50\n0\n0.000\n\n\nRudi\n100\n11\n0.110\n\n\n\n\nTable 1: pfhrp2 deletion data broken down by site\n\n\n\n\n\n\n\n\n\n\n\nWe already estimated the prevalence in the region as the mean over sites, giving \\(\\hat{p} = 0.172\\). Now we want to construct a 95% CI around this estimate. For this, we need a modified version of the Wald interval:\n\\[\n\\hat{p} \\pm z_{1 - \\alpha/2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{N} D_{\\text{eff}}}\n\\] Here, \\(N\\) is the total sample size summed over all sites, which in our case is \\(N = 725\\). The main difference from our previous version of the Wald interval is the inclusion of the design effect, \\(D_{\\text{eff}}\\). Notice that \\(D_{\\text{eff}}\\) stretches the interval, meaning a higher design effect would lead to greater uncertainty.\nComplete the following R code to calculate a 95% CI on the global prevalence using this new version of the Wald formula. Note that you still have access to previously computed variables in this code box, including n, x, p, p_global and Deff:\n\n\n# get total sample size and z\nN &lt;- \nz &lt;- 1.96\n\n# calculate margin of error\nm &lt;- \n\n# calculate lower and upper limits\nCI_lower &lt;- \nCI_upper &lt;- \n\nprint(c(CI_lower, CI_upper))\n\n\n\n\n\n# get total sample size and z\nN &lt;- sum(n)\nz &lt;- 1.96\n\n# calculate margin of error\nm &lt;- 1.96*sqrt(p_global*(1 - p_global) / N * Deff)\n\n# calculate lower and upper limits\nCI_lower &lt;- p_global - m\nCI_upper &lt;- p_global + m\n\nprint(c(CI_lower, CI_upper))\n\n\n\n\nClick to see the answer\n\nYou should find that the CI ranges from 0.073 to 0.270, or in other words from 7.3% to 27.0%.\n\n\nThis CI is considerably wider than we would have obtained if we did not take over-dispersion into account. The two intervals are shown below:\n\n\n\n\n\nIf we ignored over-dispersion and treated all observations as independent, we would be in danger of over-confidence in our global prevalence estimate.\n\n\nOver-dispersion and hypothesis testing\nSimilarly, when it comes to hypothesis testing, we have to factor over-dispersion into our analysis. For example, imagine we want to compare our global estimate of the prevalence of pfhrp2 deletions against a defined threshold of 10%. The appropriate statistical test here is the one-sample z-test for proportions, which we covered in an earlier module. However, we need to use a new formula for the test statistic (\\(Z\\)) that factors in the design effect:\n\\[\nZ = \\frac{|\\hat{p} - h|}{\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{N}D_{\\text{eff}}}}\n\\] Where \\(h\\) is the threshold we are comparing against (\\(h = 0.1\\)).\nThis can be calculated in R as follows:\n\n# define threshold\nh &lt;- 0.1\n\n# calculate test statistic\nZ &lt;- abs(p_global - h) / sqrt(p_global * (1 - p_global) / N * Deff)\nprint(Z)\n\n[1] 1.430108\n\n\nWe obtain a test statistic of \\(Z = 1.43\\). This is within the critical range \\(\\pm1.96\\), meaning we would not reject the null hypothesis. However, if we were to run the same analysis but ignoring the design effect, we would find \\(Z = 5.11\\). This is highly significant, and would result in us rejecting the null hypothesis. This is an example where over-dispersion is critically important, as it dictates the result of our hypothesis test. For something like a pfhrp2/3 study, this could mean difference between switching RDTs nationwide vs sticking with the current brand.\nDisclaimer: We do not advocate for the use of the z-test for the design pfhrp2/3 deletion studies, or the analysis of the resulting data. We will learn about a much more powerful approach to this problem in the next module.\n\n\nOver-dispersion and power\nAddressing over-dispersion is just as critical in the design stage as it is in the analysis stage. For the one-sample z-test for proportions, we already saw the formula for power in a previous module. Now, we obtain a new formula that takes \\(D_{\\text{eff}}\\) into account:\n\\[\nP_{\\text{ow}} = 1 - \\phi\\left(z_{1-\\alpha/2} - \\frac{|p - h|}{\\sqrt{\\frac{p(1-p)}{N}}D_{\\text{eff}}} \\right)\n\\] To make use of this formula, we have to assume known values for the true global prevalence \\(p\\) and also the design effect \\(D_{\\text{eff}}\\). We also have to set the total sample size \\(N\\) and the threshold \\(h\\). We will assume \\(p = 0.2\\), \\(D_{\\text{eff}} = 10\\), \\(N = 800\\) and \\(h = 0.1\\).\nWe can calculate the power under this new formula in R as follows:\n\n# define assumed parameters\np &lt;- 0.2\nDeff &lt;- 10\nN &lt;- 800\nh &lt;- 0.1\n\n# define z-values\nz_alpha &lt;- 1.96\n\n# calculate expected value of test statistic\nmu_alt &lt;- abs(p - h) / sqrt(p * (1 - p) / N * Deff)\n\n# calculate power\npower &lt;- 1 - pnorm(z_alpha - mu_alt)\nprint(power)\n\n[1] 0.6087521\n\n\nUnder this study design we only have 61% power. Contrast this with power of 99.99998% that we obtain if we ignore the design effect! Clearly the inclusion of the design effect is severely hurting our power in this analysis, however, it is better to include it and be realistic than to ignore it and obtain results that are unreliable.\n\n\nOver-dispersion and sample size\nWhen it comes to the formula for minimum sample size under the z-test, we cannot assume a known value of the design effect. This is because the design effect itself depends on the sample size, so our reasoning becomes circular. However, we can assume a known value of the ICC (\\(r\\)).\nOur new minimum sample size formula becomes:\n\\[\nn = \\frac{1 - r}{\\frac{c(p - h)^2}{(z_{1 - \\alpha/2} + z_{1 - \\beta})^2 p(1-p)} - r}\n\\]\nNote that \\(n\\) is the sample size per cluster, assuming there are \\(c\\) clusters of equal size. We can calculate this in R as follows:\n\n# define assumed parameters\np &lt;- 0.2        # prevalence of deletions\nh &lt;- 0.1        # threshold to compare against\nr &lt;- 0.05       # intra-cluster correlation\nc &lt;- 8          # number of clusters\n\n# define z-values\nz_alpha &lt;- 1.96\nz_beta &lt;- qnorm(0.8)\n\n# calculate minimum sample size\nn &lt;- (1 - r) / (c*(p - h)^2 / ((z_alpha + z_beta)^2*p*(1 - p)) - r)\n\nprint(n)\n\n[1] 69.33436\n\n\nBased on this analysis we would need 8 clusters of 70 samples. Compare this with the 8 clusters of just 16 samples we would need if we ignored intra-cluster correlation. Again, if we ignore this effect then we risk running a study that is too small, and ultimately does not have power to detect a real effect."
  },
  {
    "objectID": "tutorials/module3/activity3_power_interactive.html",
    "href": "tutorials/module3/activity3_power_interactive.html",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "",
    "text": "Welcome to Activity 3: Hypothesis Testing and Power\nIn this activity, we introduce the concept of statistical power and demonstrate its connection to null hypothesis testing. In many studies within malaria molecular surveillance, we aim to test specific hypotheses. For instance: Has the prevalence of drug resistance mutations increased over the past five years? Are certain genetic variants linked to gender, or occupation? Does treatment efficacy vary based on genetic markers? Each of these questions can be framed as a null hypothesis test. This leads us to a crucial question: given that a real effect exists, how likely is it that our study design will detect it? Statistical power is the mathematical way to calculate how likely we are to detect this real effect. We‚Äôll explore these concepts using two examples: comparing drug resistance prevalence between two time points and detecting rare genetic variants\n\n\nBy the end of this tutorial, you will be able to:\n\nDefine key terms related to null hypothesis testing.\nUse a test statistic to decide whether or not to reject a null hypothesis.\nPerform power analysis using two different statistical tests.\nInterpret power curves.\nUse minimum sample size tables.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is artificial and designed for teaching purposes only. It does not necessarily represent the real epidemiological situation in these locations."
  },
  {
    "objectID": "tutorials/module3/activity3_power_interactive.html#introduction",
    "href": "tutorials/module3/activity3_power_interactive.html#introduction",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "",
    "text": "Welcome to Activity 3: Hypothesis Testing and Power\nIn this activity, we introduce the concept of statistical power and demonstrate its connection to null hypothesis testing. In many studies within malaria molecular surveillance, we aim to test specific hypotheses. For instance: Has the prevalence of drug resistance mutations increased over the past five years? Are certain genetic variants linked to gender, or occupation? Does treatment efficacy vary based on genetic markers? Each of these questions can be framed as a null hypothesis test. This leads us to a crucial question: given that a real effect exists, how likely is it that our study design will detect it? Statistical power is the mathematical way to calculate how likely we are to detect this real effect. We‚Äôll explore these concepts using two examples: comparing drug resistance prevalence between two time points and detecting rare genetic variants\n\n\nBy the end of this tutorial, you will be able to:\n\nDefine key terms related to null hypothesis testing.\nUse a test statistic to decide whether or not to reject a null hypothesis.\nPerform power analysis using two different statistical tests.\nInterpret power curves.\nUse minimum sample size tables.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is artificial and designed for teaching purposes only. It does not necessarily represent the real epidemiological situation in these locations."
  },
  {
    "objectID": "tutorials/module3/activity3_power_interactive.html#quiz-on-hypothesis-testing-and-power",
    "href": "tutorials/module3/activity3_power_interactive.html#quiz-on-hypothesis-testing-and-power",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "Quiz on hypothesis testing and power",
    "text": "Quiz on hypothesis testing and power\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWell done on completing this quiz! We will now put some of these ideas into practice."
  },
  {
    "objectID": "tutorials/module3/activity3_power_interactive.html#testing-for-changes-in-drug-resistance-prevalence-over-time",
    "href": "tutorials/module3/activity3_power_interactive.html#testing-for-changes-in-drug-resistance-prevalence-over-time",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "Testing for changes in drug resistance prevalence over time",
    "text": "Testing for changes in drug resistance prevalence over time\nYou are a local health minister working in the Gombe region of Nigeria. You are concerned that the prevalence of antimalarial resistance may be increasing in Gombe city, the capital of Gombe state. A study conducted three years ago found that the prevalence of pfmdr1 N86Y mutations was 15%. You plan to conduct a new study to establish if there has been a significant change in the prevalence of N86Y mutations over this time.\nWe will take the previous estimate of 15% prevalence three years ago to be exact. Because we are comparing a sample against a known value, the appropriate statistical test is the one-sample z-test for proportions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe will denote the prevalence three years ago by \\(p_0 = 0.15\\). For our power analysis, we need to assume a known prevalence in the present day, which we will denote \\(p_1\\). We will be pessimistic and assume that the prevalence has doubled over the three year period, meaning \\(p_1=0.30\\). Our initial plan is to use a sample size of \\(N=150\\).\nGiven these values, we can calculate the expected value for our test statistic using the following formula: \\[\n\\mu = \\frac{|p_1 - p_0|}{\\sqrt{\\frac{p_1(1-p_1)}{N}}}\n\\] The vertical lines around \\(|p_1 - p_0|\\) mean we should take the absolute value of the difference. This ensures that \\(\\mu\\) is always positive.\nComplete the following R code to calculate the value of \\(\\mu\\):\n\n\n# input parameters\np0 &lt;- \np1 &lt;- \nN &lt;- \n\n# calculate absolute value of difference in prevalence\np_diff &lt;- abs(p1 - p0)\n\n# calculate the standard error\nSE &lt;- sqrt(p1*(1 - p1) / N)\n\n# calculate mu\nmu &lt;- \n\nprint(mu)\n\n\n\n\n\n# input parameters\np0 &lt;- 0.15\np1 &lt;- 0.3\nN &lt;- 150\n\n# calculate absolute value of difference in prevalence\np_diff &lt;- abs(p1 - p0)\n\n# calculate the standard error\nSE &lt;- sqrt(p1*(1 - p1) / N)\n\n# calculate mu\nmu &lt;- p_diff / SE\n\nprint(mu)\n\n\n\n\nClick to see the answer\n\nYou should find that \\(\\mu = 4.00\\).\n\n\nThis means that on average we should expect our test statistic to equal \\(4.00\\) if the alternative hypothesis is true. The actual value that we observe would be expected to vary around this value.\nWe can use \\(\\mu\\) to tell us our power. The formula for power under the z-test is:\n\\[\n\\text{Power} = 1 - \\phi(z_{1-\\alpha/2} - \\mu)\n\\]\nIn this formula, \\(\\phi(x)\\) refers to the area under the curve of a standard normal distribution up to the point \\(x\\). There is no simple way of calculating this value, but we can obtain it easily in R using the pnorm() function. As in previous activities, the value \\(z_{1 - \\alpha/2}\\) refers to the critical value of the normal distribution at a significance level \\(\\alpha\\) (two-tailed), which is approximately equal to 1.96.\nComplete the following R code to calculate the power under the planned study design:\n\n\n# calculate power using the known value of mu\nz &lt;- 1.96\npower &lt;- # hint, you will need to use the pnorm() function here\n\nprint(power)\n\n\n\n\n\n# calculate power using the known value of mu\nz &lt;- 1.96\npower &lt;- 1 - pnorm(z - mu)\n\nprint(power)\n\n\n\n\nClick to see the answer\n\nYou should find that \\(\\text{Power} = 0.98\\)."
  },
  {
    "objectID": "tutorials/module3/activity3_power_interactive.html#using-power-curves",
    "href": "tutorials/module3/activity3_power_interactive.html#using-power-curves",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "Using power curves",
    "text": "Using power curves\nWe have calculated that our current study design has 98% power. We normally aim for at least 80% power, meaning this study is adequately powered. In fact, we could argue that it is over-powered, meaning we could get away with using fewer samples and still have a good chance of detecting a real effect.\nWe can use power curves to explore how power changes as a function of sample size. In the plot below, the region with at least 80% power is shaded in blue.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe power analysis indicates that we may not need to sequence 150 samples after all. However, it did make the rather pessimistic assumption that prevalence has doubled from 15% to 30% over the three year period. It would be useful to repeat this analysis making different assumptions about the prevalence. One way to do this is via a series of power curves:\n\n\n\n\n\nEven a slight change in our assumption about the prevalence of N86Y mutations has a large effect on power. If we assumed present-day prevalence was 25% rather than 30% then we would need twice as many samples to achieve 80% power. This analysis was useful for exploring the exact relationship between sample size and power. However, it can be fiddly to read values off the power curve to find the exact point at which it crosses the 80% threshold. This is where sample size formulae and sample size tables come in handy."
  },
  {
    "objectID": "tutorials/module3/activity3_power_interactive.html#using-sample-size-tables",
    "href": "tutorials/module3/activity3_power_interactive.html#using-sample-size-tables",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "Using sample size tables",
    "text": "Using sample size tables\nRecall that power under the one-sample z-test for proportions was given by \\[\n\\text{Power} = 1 - \\phi\\left(z_{1-\\alpha/2} - \\frac{|p_1 - p_0|}{\\sqrt{\\frac{p_1(1-p_1)}{N}}} \\right)\n\\] Recall that in an earlier module we rearranged the formula for the Wald confidence interval to arrive at a new formula in terms of the sample size \\(N\\). Here, we want to do exactly the same thing, just with a more complicated formula! We won‚Äôt walk through the steps of this derivation, but take my word for it that this can be rearranged to produce: \\[\nN = (z_{1 - \\alpha/2} + z_{1 - \\beta})^2\\frac{p_1(1 - p_1)}{(p_1 - p_0)^2}\n\\] The only unfamiliar term here is \\(z_{1 - \\beta}\\), which is the area under the curve of the standard normal distribution up to the value \\(1 - \\beta\\). The parameter \\(\\beta\\) is one minus our power (typically \\(\\beta = 0.2\\) because minimum power is usually 0.8).\nThe following R code implements this sample size formula. Have a play around with this code. Try changing the value of p1 and see what happens to the minimum sample size. Do you obtain the value \\(N=74\\) when \\(p_2=0.3\\), like we found from the power curve? Remember that you should always round sample sizes up if they are non-integers. What happens to the sample size as p1 gets closer to 15%?\n\n\n# define our assumed values\np0 &lt;- 0.15\np1 &lt;- 0.30\n\n# define the two z parameters\nz_alpha &lt;- 1.96\nz_beta &lt;- qnorm(0.8)\n\n# calculate the minimum sample size\n(z_alpha + z_beta)^2 * p1*(1 - p1) / (p1 - p0)^2\n\n\n\nOne of the nice things about sample size formulae is that we can use them to produce tables of minimum sample sizes. Table 1 shows the minimum sample size required to achieve 80% power under different assumptions about the prevalence of N86Y mutations:\n\n\n\n\n\n\n\n\n\nAssumed present-day prevalence of N86Y mutation\nSample size\n\n\n\n\n20%\n503\n\n\n25%\n148\n\n\n30%\n74\n\n\n35%\n45\n\n\n40%\n31\n\n\n45%\n22\n\n\n50%\n17\n\n\n\n\nTable 1: minimum sample sizes under various assumptions about present-day prevalence\n\n\n\n\n\n\n\n\n\nThis allows us to scan across values and work out what is reasonable, and also what is achievable.\n\n  Reflection: \n What sample size would you opt for in this case? What factors could help you decide on a reasonable assumption for the present day prevalence of N86Y mutations? What factors could help constrain which sample sizes are feasible?"
  },
  {
    "objectID": "tutorials/module3/activity3_power_interactive.html#detecting-rare-variants",
    "href": "tutorials/module3/activity3_power_interactive.html#detecting-rare-variants",
    "title": "Activity 3: Hypothesis Testing and Power",
    "section": "Detecting rare variants",
    "text": "Detecting rare variants\nBuilding on the success of your N86Y study in Gombe city, you have been invited to conduct a new investigation focused on identifying pfk13 mutations in the nearby town of Pindiga. This study will target WHO validated mutations that are known to be associated with partial resistance to artemisinin. Instead of estimating the prevalence of these mutations, your goal is simply to determine whether any of these mutations are present in the population.\nYour will test individuals who present with malaria symptoms at a local health facility. For those who test positive for malaria, dried blood spots will be collected and subsequently sent for sequencing. However, due to limited resources, you are only able to sequence 100 samples.\nThe key question, then, is: with a sample size of only 100, is it worthwhile to pursue this study?\n\nFraming the problem as a hypothesis test\nThis type of detection study can be framed as a hypothesis test. The null hypothesis is that there are no WHO-validated mutations present in the population. In other words, the prevalence of these mutations is zero. Even a single observation of a mutant would disprove this null hypothesis. Therefore, unlike most statistical tests, there is no test statistic to calculate. Instead, we simply reject the null hypothesis if we see a single WHO-validated mutant.\nIt is straightforward to calculate power under this test. We start by assuming a known prevalence, \\(p\\), for the validated mutations. \\(p\\) is zero under the null hypothesis, and \\(p\\) must be greater than 0 under the alternative hypothesis. We will use \\(N\\) to denote the sample size. We can derive the power by following these steps:\nStep 1: Chance of a single negative result:\nThe probability that a single sample is negative (i.e.¬†does not carry a validated pfk13 mutation) is given by: \\[\n\\text{Pr}(\\text{Negative}) = 1 - p\n\\] Step 2: Chance of two negative results:\nThe probability of two negative samples is the probability of one negative sample multiplied by the probability of another negative sample: \\[\n\\begin{align}\n\\text{Pr}(\\text{Two negatives}) &= (1 - p)(1 - p) \\\\\n&= (1 - p)^2\n\\end{align}\n\\]\nStep 3: Chance of \\(N\\) negative results:\nThe probability that all \\(N\\) samples are negative is the probability of one negative sample raised to the power \\(N\\): \\[\n\\text{Pr}(N \\text{ negatives}) = (1 - p)^N\n\\] This is like saying what is the probability we observe a negative outcome \\(N\\) times. It assumes that samples are drawn independently from a much larger population.\nStep 4: Chance of at least one positive result:\nThe chance of seeing at least one positive sample is equal to one minus the probability of seeing no positive samples. If we see a positive sample then we reject the null hypothesis. Hence, this is also our power:\n\\[\n\\text{Power} = 1 - (1 - p)^N\n\\] This very simple expression can be used to guide our study design.\nComplete the following R code to implement this formula. What is our power if we assume a prevalence of 5%?\n\n\n# define parameters\np &lt;- \nN &lt;- \n\n# calculate power\npower &lt;- \n\nprint(power)\n\n\n\n\n\n# define parameters\np &lt;- 0.05\nN &lt;- 100\n\n# calculate power\npower &lt;- 1 - (1 - p)^N\n\nprint(power)\n\n\n\n\nClick to see the answer\n\nYou should find that \\(\\text{Power} = 0.994\\) if we assume a prevalence of \\(p = 0.05\\).\n\n\nBased on this result, we are over-powered to detect pfk13 mutants, meaning we can reduce the sample size. So, how many samples are needed? Rearranging our power formula to be in terms of \\(N\\) we obtain: \\[\nN = \\frac{\\text{log}(1 - \\text{Power})}{\\text{log}(1 - p)}\n\\]\nComplete the following R code to implement this sample size formula. What minimum sample size is needed if we assume a prevalence of 5% and we are aiming for 80% power?\n\n\n# define prevalence\np &lt;- \n\n# calculate minimum sample size\nN &lt;- \n\nprint(N)\n\n\n\n\n\n# define prevalence\np &lt;- 0.05\n\n# calculate minimum sample size\nN &lt;- log(1 - 0.8) / log(1 - p)\n\nprint(N)\n\n\n\n\nClick to see the answer\n\nYou should find that \\(N = 31.38\\), which would be rounded up to \\(N = 32\\).\n\n\nThis is a very promising result - we can definitely run a well-powered study within our resource constraints. However, we did make the fairly pessimistic assumption that validated pfk13 mutants are already at 5% prevalence in the population. In reality, we may want to catch them before they reach 5% in order to take pre-emptive measures. Again, we can consult a sample size table (Table 2):\n\n\n\n\n\n\n\n\n\nAssumed prevalence of pfk13 mutations\nSample size\n\n\n\n\n0.1%\n1609\n\n\n0.5%\n322\n\n\n1%\n161\n\n\n2%\n80\n\n\n3%\n53\n\n\n4%\n40\n\n\n5%\n32\n\n\n\n\nTable 2: minimum sample sizes under various assumptions about pfk13 mutation prevalence\n\n\n\n\n\n\n\n\n\n\n  Reflection: \n Based on the values in Table 2, do you think it is worthwhile to conduct this study? If you ran a study that was powered down to 2% prevalence (80 samples) and did not find any pfk13 mutants, would you be reassured by this result?"
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_interactive.html",
    "href": "tutorials/module2/activity2_MOE_interactive.html",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "",
    "text": "Welcome to Activity 2: Calculating Sample Size from Margin of Error\nIn this activity, we‚Äôll explore how margin of error (MOE) arguments can guide sample size determination. This approach relies solely on the concept of precision; larger sample sizes lead to more precise estimates. This method is invaluable not only in Malaria Molecular Surveillance (MMS) but also in epidemiology more broadly, where estimating prevalence is often a primary goal.\n\n\nBy the end of this tutorial, you will be able to:\n\nCalculate a 95% confidence interval from prevalence data.\nCalculate a minimum sample size using assumptions about prevalence and margin of error.\nAccount for drop-out and malaria positive fraction.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is artificial and designed for teaching purposes only. It does not necessarily represent the real epidemiological situation in these locations."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_interactive.html#introduction",
    "href": "tutorials/module2/activity2_MOE_interactive.html#introduction",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "",
    "text": "Welcome to Activity 2: Calculating Sample Size from Margin of Error\nIn this activity, we‚Äôll explore how margin of error (MOE) arguments can guide sample size determination. This approach relies solely on the concept of precision; larger sample sizes lead to more precise estimates. This method is invaluable not only in Malaria Molecular Surveillance (MMS) but also in epidemiology more broadly, where estimating prevalence is often a primary goal.\n\n\nBy the end of this tutorial, you will be able to:\n\nCalculate a 95% confidence interval from prevalence data.\nCalculate a minimum sample size using assumptions about prevalence and margin of error.\nAccount for drop-out and malaria positive fraction.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is artificial and designed for teaching purposes only. It does not necessarily represent the real epidemiological situation in these locations."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_interactive.html#background",
    "href": "tutorials/module2/activity2_MOE_interactive.html#background",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Background",
    "text": "Background\nYou have been recruited by the National Malaria Control Programme (NMCP) of the Democratic Republic of the Congo (DRC) to assist with study design. The NMCP is concerned about the potential spread of mutations that confer partial resistance to the drug combination Sulfadoxine-Pyrimethamine (SP). The dhps K540E mutation, known to be associated with high level SP resistance when found alongside other common mutations, has recently been found at high prevalence (72%) in neighbouring Uganda. In the last few weeks there have been anecdotal reports of SP failure in Rutshuru town, which lies in Eastern DRC close to the border with Uganda. The NMCP is concerned about possible flow of drug resistant parasites over the border.\nThe NMCP plans to conduct a cross-sectional study to estimate the prevalence of the dhps K540E mutation within Rutshuru town. Your job is to work out the appropriate sample size for this study."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_interactive.html#results-of-a-pilot-study",
    "href": "tutorials/module2/activity2_MOE_interactive.html#results-of-a-pilot-study",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Results of a pilot study",
    "text": "Results of a pilot study\nA pilot study has already been conducted in Rutshuru. This pilot study included 100 participants chosen at random from households within the town, who were tested for malaria via rapid diagnostic test (RDT). 23 people tested positive for malaria and these samples were sent away for genetic sequencing. 19 samples were successfully sequenced, of which 5 were positive for the K540E mutation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecall that we can use the following formula to calculate a 95% confidence interval on our prevalence estimate:\n\\[\n\\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}}\n\\] Complete the following R code to compute this interval:\n\n\n# estimate the prevalence\nx &lt;- \nN &lt;- \np &lt;- x / N\n\n# calculate the margin of error (MOE)\nz &lt;- 1.96\nMOE &lt;- z*sqrt(p*(1 - p) / N)\n\n# compute lower and upper 95% limits\np - MOE\np + MOE\n\n\n\n\n\n# estimate the prevalence\nx &lt;- 5\nN &lt;- 19\np &lt;- x / N\n\n# calculate the margin of error (MOE)\nz &lt;- 1.96\nMOE &lt;- z*sqrt(p*(1 - p) / N)\n\n# compute lower and upper 95% limits\nCI_lower &lt;- p - MOE\nCI_upper &lt;- p + MOE\nc(CI_lower, CI_upper)\n\n\n\n\nClick to see the answer\n\nThe 95% interval goes from 0.065 to 0.461, or in other words from 6.5% to 46.1%.\n\n\nThe 95% confidence interval reveals considerable uncertainty regarding the prevalence of K540E mutations. While our best estimate is 26.3%, the plausible range spans from 6.5% to 46.1%, which the NMCP finds too broad to be practically useful. They plan to conduct a follow-up study to obtain a more precise estimate."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_interactive.html#calculating-the-appropriate-sample-size",
    "href": "tutorials/module2/activity2_MOE_interactive.html#calculating-the-appropriate-sample-size",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Calculating the appropriate sample size",
    "text": "Calculating the appropriate sample size\nWhen designing the new study we will calculate the exact sample size needed to achieve a target margin of error (MOE). We can do this by rearranging the MOE formula to isolate the sample size (N) on the left side. If you‚Äôre comfortable with the math and would like to see the steps, follow along below. Otherwise, feel free to skip to Step 3 for the final formula.\nStep 1: Write down the formula for the MOE\nWe will use the mathematical symbol \\(m\\) for the MOE:\n\\[\nm = z_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{N}}\n\\] Step 2: Square both sides\n\\[\nm^2 = z_{1-\\alpha/2}^2 \\frac{p(1-p)}{N}\n\\] Step 3: Multiply both sides by \\(N\\) and divide by \\(m^2\\)\n\\[\nN = z_{1-\\alpha/2}^2 \\frac{p(1-p)}{m^2}\n\\]\nNow we have a new formula that we can use to determine the appropriate sample size based on assumed values of \\(p\\) and \\(m\\). Our reason for working through the derivation of this formula was to show how closely connected it is to the formula for the confidence interval. In fact, it is the same mathematical expression, just ‚Äúreverse engineered‚Äù to be in terms of \\(N\\).\nNow we need to decide what values to assume for \\(p\\) and \\(m\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor the sake of this tutorial we will assume a value of \\(p=0.26\\) to match the pilot data. The NMCP has decided that a MOE of 5% is acceptable. Complete the following R code to compute the resulting sample size:\n\n\n# enter assumed values\np &lt;- \nm &lt;- \n\n# calculate the raw sample size\nz &lt;- 1.96\nz^2*p*(1 - p) / m^2\n\n\n\n\n\n# enter assumed values\np &lt;- 0.26\nm &lt;- 0.05\n\n# calculate the raw sample size\nz &lt;- 1.96\nz^2*p*(1 - p) / m^2\n\n\n\n\nClick to see the answer\n\nWe obtain a value of 295.65. We would round this up to \\(N=296\\) to give a whole number.\n\n\nOne of the nice things about sample size determination is that we can easily check that our calculation is correct. Optional exercise: Try entering the values \\(p=0.26\\) and \\(N=296\\) into the 95% CI formula that we used in the pilot data analysis. If our calculations were correct, you should find that the resulting MOE is very close to 5%.\n\n\n# Copy over the Wald formula code from the previous section, and edit to reflect\n# the new assumed prevalence of 26% and sample size of 296\n\n\n\n\n\n# enter assumed values\np &lt;- 0.26\nN &lt;- 296\n\n# calculate the margin of error (MOE)\nz &lt;- 1.96\nz*sqrt(p*(1 - p) / N)\n\n\n\n\nClick to see the answer\n\nYou should obtain a margin of error of 4.997%, which is very close to the target 5%. Notice that our MOE will always be equal or smaller than the target MOE. This is because we rounded the sample size up from 295.65 to 296."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_interactive.html#buffering",
    "href": "tutorials/module2/activity2_MOE_interactive.html#buffering",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Buffering",
    "text": "Buffering\nBuffering refers to increasing a sample size to allow for drop-out (loss of samples). Some ways that drop-out can occur are through:\n\nParticipants withdrawing consent\nParticipants dying or leaving the area\nSamples being lost during transportation\nSamples becoming contaminated\nSamples failing amplification or sequencing resulting in a lack of genetic data\nData being lost due to data storage errors\n\nWe cannot completely eliminate the risk of drop-out, but by buffering sample sizes we can at least be robust to it. If we expect a proportion \\(d\\) of samples to be lost, then the formula for buffered sample size is:\n\\[\nN_{\\text{buffered}} = \\frac{N_{\\text{original}}}{1 - d}\n\\]\nThrough consulting with lab technicians and the study team, you estimate that 10% of samples may be lost to drop-out. Complete the following R code to come up with a buffered sample size:\n\n\n# enter sample size and estimated drop-out\nN &lt;- 296\nd &lt;- 0.1\n\n# calculate the buffered sample size\nN_buffered &lt;- \n\nprint(N_buffered)\n\n\n\n\n\n# enter sample size and estimated drop-out\nN &lt;- 296\nd &lt;- 0.1\n\n# calculate the buffered sample size\nN_buffered &lt;- N / (1 - d)\n\nprint(N_buffered)\n\n\n\n\nClick to see the answer\n\nYou should obtain a buffered sample size of 328.89, which we would round up to 329."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_interactive.html#accounting-for-positive-fraction",
    "href": "tutorials/module2/activity2_MOE_interactive.html#accounting-for-positive-fraction",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Accounting for positive fraction",
    "text": "Accounting for positive fraction\nSo far, we have focused on working out how many confirmed malaria cases we need in our study. However, recall that this will be a cross-sectional study with individuals being sampled at random from households within Rutshuru town. Many of the individuals tested will be negative for malaria. It may be useful for the study team to know how many individuals they need to test as part of this study, which may be considerably higher than the number of confirmed malaria cases.\nThe NMCP estimates that 25% of the population of Rutshuru will be positive for malaria by RDT. We can use the same buffering formula as before, but now using the positive fraction (\\(f\\)) to inflate our sample size:\n\\[\nN_{\\text{test}} = \\frac{N_{\\text{confirmed}}}{f}\n\\]\nNote that this is in addition to buffering for drop-out. We can imagine a chain of events where we can lose samples at each stage; we want to ensure that in the end we still have enough samples remaining.\nComplete the following R code to work out the number of people we will need to test to achieve the final target sample size:\n\n\n# enter buffered sample size and positive fraction\nN &lt;- \nf &lt;- \n\n# calculate the testing sample size\nN_test &lt;- \n\nprint(N_test)\n\n\n\n\n\n# enter buffered sample size and positive fraction\nN &lt;- 329\nf &lt;- 0.25\n\n# calculate the testing sample size\nN_test &lt;- N / f\n\nprint(N_test)\n\n\n\n\nClick to see the answer\n\nYou should find that 1316 people need to be tested.\n\n\nYou have now completed your study design exercise. Your recommendation to the NMCP is as follows:\nAssuming a prevalence of K540E mutations of 26% based on pilot data, a sample size of 329 confirmed malaria cases will be needed to estimate prevalence to within 5% margin of error. This number is buffered to allow for 10% drop-out.\nAssuming that malaria prevalence is 25% by RDT in Rutshuru town, this translates to 1316 individuals who will need to be tested in the cross-sectional study design."
  },
  {
    "objectID": "tutorials/module2/activity2_MOE_interactive.html#bonus-questions",
    "href": "tutorials/module2/activity2_MOE_interactive.html#bonus-questions",
    "title": "Activity 2: Calculating Sample Size from Margin of Error",
    "section": "Bonus questions",
    "text": "Bonus questions\nThe study design above is based on strong statistical principles. However, it is worth testing how robust these numbers are to changes in our assumptions.\nUnder the chosen sample size of 296 (after drop-out), what would be your margin of error under the worst case scenario that the true prevalence of the K540E mutation was actually 50%?\n\n\n\n\n\n\n\n# enter assumed values\np &lt;- 0.5\nN &lt;- 296\n\n# calculate the margin of error (MOE)\nz &lt;- 1.96\nz*sqrt(p*(1 - p) / N)\n\n\n\n\nClick to see the answer\n\nThe MOE would increase to 5.7% in the most pessimistic scenario.\n\n\nWe estimated that 1316 people will need to be tested based on an assumed 25% prevalence of malaria. But what if during the study we find that this assumption was not correct, and malaria prevalence is actually only 15% in Rutshuru town? What would be your expected final sample size, and what would be your resulting MOE?\n\n\n\n\n\n\n\n# enter assumed values\np &lt;- 0.26\nN_test &lt;- 1316\n\n# work out final sample size assuming 15% prevalence and 10% drop-out\nN &lt;- round(N_test * 0.15 * 0.9)\nprint(N)\n\n# calculate the margin of error (MOE)\nz &lt;- 1.96\nz*sqrt(p*(1 - p) / N)\n\n\n\n\nClick to see the answer\n\nAssuming 15% prevalence and 10% drop-out, our final sample size of successfully sequenced malaria cases would be around 178. This would result in a MOE of 6.4%."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower.html",
    "href": "tutorials/module5/module5_DRpower.html",
    "title": "Module 5: The DRpower Tool",
    "section": "",
    "text": "This activity demonstrates the use of the DRpower R package and the accompanying web-based tool. In this activity you will learn:\n\nHow to design a multi-cluster pfhrp2/3 deletion study.\nHow to analyse and interpret the results of a pfhrp2/3 deletion study.\nHow to account for intra-cluster correlation in other study designs, such as prevalence surveys and presence/absence studies.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is artificial and designed for teaching purposes only. It does not necessarily represent the real epidemiological situation in these locations."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower.html#learning-outcomes",
    "href": "tutorials/module5/module5_DRpower.html#learning-outcomes",
    "title": "Module 5: The DRpower Tool",
    "section": "",
    "text": "This activity demonstrates the use of the DRpower R package and the accompanying web-based tool. In this activity you will learn:\n\nHow to design a multi-cluster pfhrp2/3 deletion study.\nHow to analyse and interpret the results of a pfhrp2/3 deletion study.\nHow to account for intra-cluster correlation in other study designs, such as prevalence surveys and presence/absence studies.\n\nDisclaimer: The scenarios in this document are entirely fictitious. While real place names are used, the data itself is artificial and designed for teaching purposes only. It does not necessarily represent the real epidemiological situation in these locations."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower.html#designing-a-multi-cluster-pfhrp23-deletion-study-in-ethiopia",
    "href": "tutorials/module5/module5_DRpower.html#designing-a-multi-cluster-pfhrp23-deletion-study-in-ethiopia",
    "title": "Module 5: The DRpower Tool",
    "section": "Designing a multi-cluster pfhrp2/3 deletion study in Ethiopia",
    "text": "Designing a multi-cluster pfhrp2/3 deletion study in Ethiopia\n\nBackground\nYou have been tasked by the Ethiopian National Malaria Control Programme (NMCP) to assist with design and implementation of a study into pfhrp2/3 deletions. Following the WHO 2020 recommendation, this study will be multi-site and conducted at a regional level. It will establish whether the prevalence of pfhrp2 deletions among clinical malaria cases is significantly above the 5% threshold. If so, this will trigger a nationwide switch in rapid diagnostic tests (RDTs) away from tests that rely exclusively on the HRP2 protein.\nA full study of this sort would normally be run in parallel over multiple regions, however, for the purposes of this tutorial we will focus exclusively on the Amhara region.\n\n\nUsing sample size tables\nFirst, we need to scope out roughly how many sites and how many samples are required. The easiest way to do this is via pre-calculated sample size tables. Go to the pfhrp2/3 Planner and navigate to the Explore tab. You should see a sample size table with the number of sites (health facilities) in rows, and the assumed prevalence of pfhrp2/3 deletions in columns.\nIn any power analysis, we must begin by assuming a known effect size under the alternative hypothesis. For this study, that means selecting an assumed prevalence of pfhrp2/3 deletions in the population. This assumption can be challenging and may feel somewhat arbitrary. It‚Äôs important to remember that as the assumed prevalence approaches the 5% detection threshold, the required sample size increases significantly. Conversely, assuming a very high prevalence may reduce the public health relevance of the study by focusing power on detecting only large shifts in the parasite population‚Äîchanges that could already be affecting clinical diagnosis.\nTo balance these factors, we recommend a default assumed prevalence of 10%. This value provides a reasonable sensitivity level while keeping sample sizes manageable. For more insights on selecting this parameter, refer to the FAQ section in the web-based pfhrp2/3 Planner.\nQuestion: What is the total sample size needed (over all clusters) if we recruit 5 clusters?\nOptions:\n\n2480 (correct)\n678\n408\n300\n\nQuestion: What about if we recruit 10 clusters?\nOptions:\n\n2480\n678\n408\n300 (correct)\n\nAs the number of sites recruited increases, the total sample size needed actually decreases. This may seem counterintuitive, as we might expect that adding more clusters would inherently make the study larger. What‚Äôs happening here is that with more clusters, the samples become more independent. By sampling from a greater number of distinct sites, we reduce the likelihood of repeatedly sampling from the same sub-population, thereby minimizing the impact of intra-cluster correlation. As a result, fewer samples are needed overall to achieve the same level of statistical power.\n\n\nFactoring in financial considerations\nThe Ethiopian NMCP has provided you with rough estimates of the costs of various aspects of the planned study, including the costs of RDT testing, microscopy, staff time, transport of samples and training of staff. They estimate it will cost $500 USD per cluster recruited, plus an additional $6 USD per sample enrolled.\nQuestion: Based on these financial figures, and using the numbers from the sample size table, how many clusters should you recruit to minimize the total cost?\nOptions:\n\n2\n5\n7 (correct)\n10\n\nThe design with 7 clusters comes in at $6,365 UDS total. This is made up of $3,500 for setting up the clusters plus $2,856 for the samples enrolled. This is the cheapest of the possible options, although between 6 and 10 clusters are quite similar total costs and may also be viable options.\n\n\nSelecting sites\nNext, we have to choose how we will select the 7 sites. Common choices are 1) sentinel site surveillance, where known and established sites are chosen based on feasibility, and 2) random selection, where a complete list of all health facilities is compiled and a defined number of sites is drawn at random from this list.\nSome advantages of sentinel site surveillance include:\n\nConsistency and Comparability Over Time: Sentinel sites are typically chosen for long-term monitoring, enabling consistent data collection over time. This allows for more precise trend analysis and easier comparisons of changes in disease prevalence.\nCost-Effectiveness and Established Infrastructure: Sentinel sites are often strategically chosen for accessibility and logistical ease, making them more cost-effective than random site selection, which may require travel to remote or difficult-to-reach locations. Additionally, these sites usually have established infrastructure, trained personnel, and local relationships, streamlining data collection and improving data quality..\nTargeting High-Burden or Priority Areas: Sentinel sites are often selected based on epidemiological significance, such as higher disease burden or strategic relevance for outbreak monitoring. This targeted approach can be advantageous in understanding and responding to disease patterns in high-risk areas, which might be overlooked in a random selection approach.\n\nOn the other hand, there are some advantages of random site selection:\n\nImproved Representativeness and Reduced Selection Bias: Random site selection from a complete list provides a more representative sample of the population and minimizes biases associated with known sentinel sites, which are often chosen based on specific criteria like accessibility or historical disease burden. This approach enhances the validity and generalizability of prevalence estimates, making them more applicable across various areas, including those not included in the survey.\nGreater Diversity of Environmental Conditions: Randomly selected sites are more likely to capture a range of environmental, socio-economic, and health system conditions. This variation is crucial for understanding factors that influence disease prevalence and for developing interventions that can apply across diverse settings.\n\nQuestion: Which of these designs would you choose for this study?\nOptions:\n\nSentinel site surveillance (both answers correct)\nRandom sampling (both answers correct)\n\nFor the sake of this tutorial we will go with random selection of sites. A complete list of all health facilities in the Amhara region is compiled, and 7 sites are selected from this list at random. Table 1 gives the chosen sites and the target sample size based on our initial calculations.\n\n\n\n\n\n\n\n\n\nSite name\nSample size\n\n\n\n\nDese\n68\n\n\nMotta\n68\n\n\nDebark\n68\n\n\nMetema\n68\n\n\nChagni\n68\n\n\nFinote Selam\n68\n\n\nAlem Ketema\n68\n\n\n\n\nTable 1: target sample sizes based on initial exploration\n\n\n\n\n\n\n\n\n\n\n\nRefining sample sizes\nWith a preliminary study plan in place, we can now incorporate some real-world constraints. After discussions with site leads at each of the seven locations, we‚Äôve learned that several sites may face challenges in reaching the target sample size. This could stem from factors like limited staffing, low malaria incidence, or other local issues. To address this, you‚Äôve adjusted the sample sizes by increasing recruitment targets at sites where it is feasible to do so. Here‚Äôs the updated sample size table:\n\n\n\n\n\n\n\n\n\nSite name\nSample size\n\n\n\n\nDese\n100\n\n\nMotta\n30\n\n\nDebark\n70\n\n\nMetema\n55\n\n\nChagni\n90\n\n\nFinote Selam\n70\n\n\nAlem Ketema\n60\n\n\n\n\nTable 2: target sample sizes factoring in constraints\n\n\n\n\n\n\n\n\n\nBut now we are faced with a problem - how do we know if this new design still has adequate power? We can no longer rely on sample size tables, which assume the same sample size per cluster. On the other hand, we cannot simply assume that power will be adequate. This is where the Design tab of the pfhrp2/3 Planner becomes useful.\nDownload a .csv file with the current study plan from here. You can then upload this spreadsheet into the we app using the ‚ÄúUpload a .csv file‚Äù option. You should find that the table populates with these values.\nYou‚Äôll notice that drop-out is also considered at this stage. We are assuming 10% drop-out in each site, but for a more rigorous approach you may want to factor in different drop-out levels by site. When you click ‚ÄúCalculate adjusted sample sizes‚Äù you should see a table that contains the adjusted sample size, buffered for drop-out.\nNow we are ready to estimate power. On the same page you will find drop-down menus where you can set the assumed prevalence of pfhrp2/3 deletions and the intra-cluster correlation. When you git the ‚ÄúEstimate power‚Äù button the tool will run a simulation-based power analysis (this may take a few seconds). Because this result is simulation-based we only get an estimate of the power, and not an exact figure. If you want a more precise estimate you can try increasing the number of simulations, although this will take longer to run.\nQuestion: Do you think power is adequate under the current plan?\nOptions:\n\nYes (correct)\nNo\n\nRunning an estimate with 1000 simulations should show that the study‚Äôs power is close to 80%, with the 95% confidence interval likely spanning this target. For future reference, you can download a copy of your power analysis from the ‚ÄúGenerate report‚Äù tab. Based on these results, the study plan appears statistically sound and ready for consideration. However, final approval should also take into account logistical and financial factors to ensure feasibility."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower.html#analyzing-pfhrp23-data",
    "href": "tutorials/module5/module5_DRpower.html#analyzing-pfhrp23-data",
    "title": "Module 5: The DRpower Tool",
    "section": "Analyzing pfhrp2/3 data",
    "text": "Analyzing pfhrp2/3 data\nSome time later, the Ethiopian NMCP request your assistance once again to analyse the results of the pfhrp2/3 deletion study, which was carried out according to your plan. The results of the study are shown in Table 3.\n\n\n\n\n\n\n\n\n\n\nSite name\npfhrp2 negative\nSample size\n\n\n\n\nDese\n10\n100\n\n\nMotta\n1\n30\n\n\nDebark\n9\n70\n\n\nMetema\n7\n55\n\n\nChagni\n2\n90\n\n\nFinote Selam\n2\n70\n\n\nAlem Ketema\n8\n60\n\n\n\n\nTable 3: results of the pfhrp2/3 study\n\n\n\n\n\n\n\n\n\n\nYou can download these results in .csv form here. The easiest way to analyse these data is via the Analysis tab of the pfhrp2/3 Planner. Select ‚ÄúUpload a .csv file‚Äù and import the data.\nNow click the ‚ÄúEstimate prevalence‚Äù button to perform a Bayesian analysis of the data. This analysis takes into account the intra-cluster correlation in the data, which is estimated and accounted for in the prevalence estimate. Therefore there is no need to estimate a design effect or effective sample size as this is accounted for automatically.\nYou will also see a ‚ÄúProbability above threshold‚Äù field. This tells us the probability that the prevalence is above the 5% threshold.\nQuestion: Which of these is true:\nOptions:\n\nThere is less than 95% probability that the prevalence is above the 5% threshold. Therefore we conclude that the prevalence is below 5%.\nThere is more than 95% probability that the prevalence is above the 5% threshold. Therefore we conclude that the prevalence is above 5%. (correct)\n\nIn this example, we have sufficient evidence to conclude that the prevalence of pfhrp2/3 deletions in the Amhara region is above the 5% threshold. Therefore, according to the WHO 2020 recommendation, we would be justified in switching RDTs to a brand that does not rely exclusively on the HRP2 protein.\n\nEstimating the ICC\nAs noted above, the DRpower method automatically accounts for ICC when estimating prevalence, so a separate ICC estimate is not strictly necessary. However, obtaining an ICC estimate can still be valuable for future study planning. It‚Äôs a straightforward process and contributes to a broader understanding of ICC levels, which can benefit researchers planning similar studies in the future or in neighbouring regions.\nStill on the Analysis tab, scroll down to the ‚ÄúEstimate ICC‚Äù button. Clicking this button gives an estimate of the ICC, including a point estimate and a 95% CrI.\nQuestion: Based on the ICC analysis, which of these is true:\nOptions:\n\nThere is strong evidence that the ICC is below 0.2 **(correct)*\nThere is strong evidence that the ICC is below 0.1\nThere is strong evidence that the ICC is below 0.05\nThere is strong evidence that the ICC is zero (complete independence)\n\nWe can navigate to the ‚ÄúGenerate report‚Äù tab to download a report detailing our analysis.\n\n\nRecap key points\nOur pfhrp2/3 analysis is now complete. We began with a well-powered study design, carefully crafted to be robust and realistic. By accounting for varying sample sizes across sites and anticipating potential drop-out, we reinforced the reliability of our approach. Beyond statistical considerations, we incorporated logistical and financial constraints to ensure the study‚Äôs feasibility. Importantly, we accounted for possible over-dispersion at both the design and analysis stages, increasing our confidence in the results. Ultimately, this rigorous approach allows us to conclude with confidence that the prevalence of pfhrp2/3 deletions exceeds the 5% threshold‚Äîa finding with significant implications for malaria control at the national level."
  },
  {
    "objectID": "tutorials/module5/module5_DRpower.html#bonus-questions",
    "href": "tutorials/module5/module5_DRpower.html#bonus-questions",
    "title": "Module 5: The DRpower Tool",
    "section": "Bonus questions",
    "text": "Bonus questions\nThe DRpower R package is primarily designed with pfhrp2/3 studies in mind, but also contains some functions that are useful for other multi-cluster designs. For example, it can be used when estimating prevalence to within a specified margin of error, or when detecting the presence of rare variants, while taking into account intra-cluster correlation. These features are only present in the R package, and are not present on the web-based pfhrp2/3 Planner.\nThe following R code calculates the sample size needed for a multi-cluster prevalence survey to reach a target margin of error. Try varying the value of the ICC and see how this impacts sample size.\n\n# calculate sample size needed to achieve a target MOE\nDRpower::get_sample_size_margin(MOE = 0.1, n_clust = 10, prevalence = 0.2, ICC = 0.01)\n\n[1] 7\n\n\nUntil now, we have focused on using the Wald interval to construct a 95% confidence interval (CI). Although the Wald interval is straightforward to calculate, it relies on assumptions that may not always hold. For instance, with a small sample size or when prevalence is near 0 or 1, the Wald interval can extend beyond logical boundaries, producing values below 0 or above 1. Such results are nonsensical and indicate that the interval may not accurately represent the underlying data.\nAn alternative approach is to use the Clopper-Pearson (CP) interval. Unlike the Wald interval, the CP interval remains within the 0 to 1 range, making it more statistically robust. However, this robustness comes with a trade-off: the CP interval tends to be conservative, resulting in wider intervals.\nPlay around with the following R code, which still aims to reach a target margin of error but now assuming CP intervals. What do you notice about the sample size compared to the simple Wald interval approach?\n\n# calculate sample size needed to achieve a target MOE using CP intervals\nDRpower::get_sample_size_margin_CP(MOE = 0.1, n_clust = 10, prevalence = 0.2, ICC = 0.01)\n\n[1] 10\n\n\nFinally, we may want to look for the presence of rare variants in a multi-cluster design while accounting for intra-cluster correlation.\nPlay around with the following code. What total sample size would you need if you assume 10 clusters, 1% prevalence of the variant of interest, and an ICC of 0.05? How would this compare to the total sample size if you treated all sites as independent?\n\n# calculate sample size needed in a multi-cluster presence/absence study\nDRpower::get_sample_size_presence(n_clust = 5, prevalence = 0.05, ICC = 0.05)\n\n[1] 8"
  },
  {
    "objectID": "tutorials/module6/sheet_1_tz.html",
    "href": "tutorials/module6/sheet_1_tz.html",
    "title": "Fact sheet: Epidemiologist",
    "section": "",
    "text": "As the epidemiologist on the team, your job is to help your team make informed decisions on the target population and study design considerations, including:\n\nSelect appropriate regions and health facilities.\nDecide on the number of clusters (health facilities) to include.\nUse expected malaria cases per month and test positivity rates to plan enrollment.\n\nNavigate back to the group activity instructions if you need to!\n\n\nUse the buttons to download as .csv or .xls if you prefer"
  },
  {
    "objectID": "tutorials/module6/sheet_1_tz.html#your-role",
    "href": "tutorials/module6/sheet_1_tz.html#your-role",
    "title": "Fact sheet: Epidemiologist",
    "section": "",
    "text": "As the epidemiologist on the team, your job is to help your team make informed decisions on the target population and study design considerations, including:\n\nSelect appropriate regions and health facilities.\nDecide on the number of clusters (health facilities) to include.\nUse expected malaria cases per month and test positivity rates to plan enrollment.\n\nNavigate back to the group activity instructions if you need to!\n\n\nUse the buttons to download as .csv or .xls if you prefer"
  },
  {
    "objectID": "tutorials/module6/sheet_3_cb.html",
    "href": "tutorials/module6/sheet_3_cb.html",
    "title": "Fact sheet: Budget officer",
    "section": "",
    "text": "As the budget officer on the team, your job is to help your team make informed decisions on costing and study design considerations, including:\n\nChoosing (and potentially limiting) the number of regions or health facilities.\nAdjusting sample sizes, number of clusters, and timelines.\nConducting cost calculations, for example:\n\nTotal Fixed Costs = Number of HFs √ó (Fixed Cost per HF + Transport Cost per HF)\nTotal Variable Costs = Total Samples Enrolled √ó Variable Cost per Sample Enrollment Rate\n\n\nDo your best job to stay within your budget!\nNavigate back to the group activity instructions if you need to!\n\n\n\n\n\n\n\n\n\n\nCost item\nCost\nDescription\n\n\n\n\nFixed cost per health facility enrolled\n$5,000\nIncludes training, equipment, and administrative expenses.\n\n\nCost per sample enrolled\n$55\nIncludes collection, laboratory testing, consumables, and data management.\n\n\n\n\n\n\n\n\n\nRegion\nTransport cost per health facility\n\n\n\n\nCoastal Region\n$1,000\n\n\nHighland Region\n$1,500\n\n\nForest Region\n$2,500\n\n\nUrban Region\n$800"
  },
  {
    "objectID": "tutorials/module6/sheet_3_cb.html#your-role",
    "href": "tutorials/module6/sheet_3_cb.html#your-role",
    "title": "Fact sheet: Budget officer",
    "section": "",
    "text": "As the budget officer on the team, your job is to help your team make informed decisions on costing and study design considerations, including:\n\nChoosing (and potentially limiting) the number of regions or health facilities.\nAdjusting sample sizes, number of clusters, and timelines.\nConducting cost calculations, for example:\n\nTotal Fixed Costs = Number of HFs √ó (Fixed Cost per HF + Transport Cost per HF)\nTotal Variable Costs = Total Samples Enrolled √ó Variable Cost per Sample Enrollment Rate\n\n\nDo your best job to stay within your budget!\nNavigate back to the group activity instructions if you need to!\n\n\n\n\n\n\n\n\n\n\nCost item\nCost\nDescription\n\n\n\n\nFixed cost per health facility enrolled\n$5,000\nIncludes training, equipment, and administrative expenses.\n\n\nCost per sample enrolled\n$55\nIncludes collection, laboratory testing, consumables, and data management.\n\n\n\n\n\n\n\n\n\nRegion\nTransport cost per health facility\n\n\n\n\nCoastal Region\n$1,000\n\n\nHighland Region\n$1,500\n\n\nForest Region\n$2,500\n\n\nUrban Region\n$800"
  },
  {
    "objectID": "tutorials/module6/sheet_1_cb.html",
    "href": "tutorials/module6/sheet_1_cb.html",
    "title": "Fact sheet: Epidemiologist",
    "section": "",
    "text": "As the epidemiologist on the team, your job is to help your team make informed decisions on the target population and study design considerations, including:\n\nSelect appropriate regions and health facilities.\nDecide on the number of clusters (health facilities) to include.\nUse expected malaria cases per month and test positivity rates to plan enrollment.\n\nNavigate back to the group activity instructions if you need to!\n\n\nUse the buttons to download as .csv or .xls if you prefer"
  },
  {
    "objectID": "tutorials/module6/sheet_1_cb.html#your-role",
    "href": "tutorials/module6/sheet_1_cb.html#your-role",
    "title": "Fact sheet: Epidemiologist",
    "section": "",
    "text": "As the epidemiologist on the team, your job is to help your team make informed decisions on the target population and study design considerations, including:\n\nSelect appropriate regions and health facilities.\nDecide on the number of clusters (health facilities) to include.\nUse expected malaria cases per month and test positivity rates to plan enrollment.\n\nNavigate back to the group activity instructions if you need to!\n\n\nUse the buttons to download as .csv or .xls if you prefer"
  },
  {
    "objectID": "tutorials/module6/statistician_sheet_cb.html",
    "href": "tutorials/module6/statistician_sheet_cb.html",
    "title": "Fact sheet: Statistician",
    "section": "",
    "text": "As the statistician on the team, your job is to help your team make informed decisions on study design considerations, including:\n\nDecide on the number of clusters (health facilities) to include.\nBuffer for drop-out.\nDetermining the necessary sample size and power for primary and secondary endpoints.\nAdjust for ICC."
  },
  {
    "objectID": "tutorials/module6/statistician_sheet_cb.html#your-role",
    "href": "tutorials/module6/statistician_sheet_cb.html#your-role",
    "title": "Fact sheet: Statistician",
    "section": "",
    "text": "As the statistician on the team, your job is to help your team make informed decisions on study design considerations, including:\n\nDecide on the number of clusters (health facilities) to include.\nBuffer for drop-out.\nDetermining the necessary sample size and power for primary and secondary endpoints.\nAdjust for ICC."
  },
  {
    "objectID": "tutorials/module6/statistician_sheet_cb.html#available-data",
    "href": "tutorials/module6/statistician_sheet_cb.html#available-data",
    "title": "Fact sheet: Statistician",
    "section": "Available data",
    "text": "Available data\nIn order to help you perform these critical calculations, we have pre-loaded all the fact sheets and data that your various team members have access to.\nThis includes:\n\nepi: data on malaria prevalence, incidence and test positivity rate\nhealth_facilities: data on health facilities in each region, the population they serve, and expected malaria cases per month\n\ncost_per_hf: fixed cost per health facility enrolled (in USD), including training, equipment, and administrative expenses.\ncost_per_sample: cost per sample enrolled (in USD), including collection, laboratory testing, consumables, and data management\ncost_transport_coast: transport cost per health facility (in USD) in the Coastal region\ncost_transport_highland: transport cost per health facility (in USD) in the Highland region\ncost_transport_forest: transport cost per health facility (in USD) in the Forest region\ncost_transport_urban: transport cost per health facility (in USD) in the Urban region\n\n\nExercise\nYou can use the below R code box to perform your calculations"
  },
  {
    "objectID": "tutorials/module6/scenario3.html",
    "href": "tutorials/module6/scenario3.html",
    "title": "Scenario 3",
    "section": "",
    "text": "You have been recruited by the National Malaria Control Programme (NMCP) of Cambodia to assist with study design. The NMCP is concerned about the potential spread of mutations that affect the performance of HRP2-based rapid diagnostic tests (RDTs). pfhrp2 deletions can cause false-negative results in HRP2-based RDTs. In the last few weeks, there have been anecdotal reports of RDT failures in border towns, particularly in the Forest region. Additionally, there are concerns about the emergence of artemisinin resistance due to a new pfk13 mutation, as neighboring countries have reported its increasing prevalence. Confirming whether this rare mutation is present in Cambodia is a priority for the NMCP. The NMCP plans to conduct a cross-sectional study to estimate the prevalence of pfhrp2 deletions and detect the pfk13 mutation. The NMCP are also interested to know the prevalence of other drug resistance mutations, such as pfdhps, pfdhfr and pfcrt mutations so these are secondary outcomes of interest."
  },
  {
    "objectID": "tutorials/module6/scenario3.html#background",
    "href": "tutorials/module6/scenario3.html#background",
    "title": "Scenario 3",
    "section": "",
    "text": "You have been recruited by the National Malaria Control Programme (NMCP) of Cambodia to assist with study design. The NMCP is concerned about the potential spread of mutations that affect the performance of HRP2-based rapid diagnostic tests (RDTs). pfhrp2 deletions can cause false-negative results in HRP2-based RDTs. In the last few weeks, there have been anecdotal reports of RDT failures in border towns, particularly in the Forest region. Additionally, there are concerns about the emergence of artemisinin resistance due to a new pfk13 mutation, as neighboring countries have reported its increasing prevalence. Confirming whether this rare mutation is present in Cambodia is a priority for the NMCP. The NMCP plans to conduct a cross-sectional study to estimate the prevalence of pfhrp2 deletions and detect the pfk13 mutation. The NMCP are also interested to know the prevalence of other drug resistance mutations, such as pfdhps, pfdhfr and pfcrt mutations so these are secondary outcomes of interest."
  },
  {
    "objectID": "tutorials/module6/scenario3.html#your-task",
    "href": "tutorials/module6/scenario3.html#your-task",
    "title": "Scenario 3",
    "section": "Your task",
    "text": "Your task\nThe NMCP has a budget of USD 500,000. There are four regions in Cambodia (Coastal, Highland, Forest, and Urban) each with 25 health facilities. From previous studies conducted by the NMCP, we know that the intra-cluster correlation is 0.1. Your job is to design a study powered for the following end-points:\n\nPrimary endpoints\n\nEstimate the prevalence of pfhrp2 deletions causing false-negative RDTs\nDetect the new pfk13 mutation associated with artemisinin resistance.\n\nSecondary endpoint\n\nEstimate the prevalence of pfdhps, pfdhfr and pfcrt mutations.\n\n\nEach team member has key information on the epidemiological context, health facilities in each region, costing and sample size considerations (ICC, etc). Click on your role to access this information. Work in parellel (but together) to develop your study design!\n\n Epidemiologist: Provide insights on disease prevalence and high-risk areas.\n Health Facility Coordinator: Offer logistical information about facilities.\n Budget Officer: Manage financial aspects and calculate costs.\n Statistician (1-2 people): Handle sample size calculations and adjust for ICC."
  },
  {
    "objectID": "tutorials/module6/scenario1.html",
    "href": "tutorials/module6/scenario1.html",
    "title": "Scenario 1",
    "section": "",
    "text": "You have been recruited by the National Malaria Control Programme (NMCP) of Tanzania to assist with study design. The NMCP is concerned about the potential spread of mutations that affect the performance of HRP2-based rapid diagnostic tests (RDTs). pfhrp2 deletions can cause false-negative results in HRP2-based RDTs. In the last few weeks, there have been anecdotal reports of RDT failures in border towns, particularly in the South Region. Additionally, there are concerns about the emergence of artemisinin resistance due to pfk13 mutations, as neighboring countries have reported detection of these mutations. Confirming whether these rare mutations are present in Tanzania is a priority for the NMCP. The NMCP plans to conduct a cross-sectional study to estimate the prevalence of pfhrp2 deletions and detect pfk13 mutations. The NMCP are also interested to know the prevalence of other drug resistance mutations, such as pfdhps, pfdhfr and pfcrt mutations so these are secondary outcomes of interest."
  },
  {
    "objectID": "tutorials/module6/scenario1.html#background",
    "href": "tutorials/module6/scenario1.html#background",
    "title": "Scenario 1",
    "section": "",
    "text": "You have been recruited by the National Malaria Control Programme (NMCP) of Tanzania to assist with study design. The NMCP is concerned about the potential spread of mutations that affect the performance of HRP2-based rapid diagnostic tests (RDTs). pfhrp2 deletions can cause false-negative results in HRP2-based RDTs. In the last few weeks, there have been anecdotal reports of RDT failures in border towns, particularly in the South Region. Additionally, there are concerns about the emergence of artemisinin resistance due to pfk13 mutations, as neighboring countries have reported detection of these mutations. Confirming whether these rare mutations are present in Tanzania is a priority for the NMCP. The NMCP plans to conduct a cross-sectional study to estimate the prevalence of pfhrp2 deletions and detect pfk13 mutations. The NMCP are also interested to know the prevalence of other drug resistance mutations, such as pfdhps, pfdhfr and pfcrt mutations so these are secondary outcomes of interest."
  },
  {
    "objectID": "tutorials/module6/scenario1.html#your-task",
    "href": "tutorials/module6/scenario1.html#your-task",
    "title": "Scenario 1",
    "section": "Your task",
    "text": "Your task\nThe NMCP has a budget of USD 500,000. There are four regions in Tanzania (North, South, East and West) each with 25 health facilities. From previous studies conducted by the NMCP, we know that the intra-cluster correlation is 0.1. Your job is to design a study powered for the following end-points:\n\nPrimary endpoints\n\nEstimate the prevalence of pfhrp2 deletions causing false-negative RDTs\nDetect pfk13 mutations associated with artemisinin resistance.\n\nSecondary endpoint\n\nEstimate the prevalence of pfdhps, pfdhfr and pfcrt mutations.\n\n\nEach team member has key information on the epidemiological context, health facilities in each region, costing and sample size considerations (ICC, etc). Click on your role to access this information. Work in parellel (but together) to develop your study design!\n\n Epidemiologist: Provide insights on disease prevalence and high-risk areas.\n Health Facility Coordinator: Offer logistical information about facilities.\n Budget Officer: Manage financial aspects and calculate costs.\n Statistician (1-2 people): Handle sample size calculations and adjust for ICC."
  },
  {
    "objectID": "tutorials/module6/sheet_2_tz.html",
    "href": "tutorials/module6/sheet_2_tz.html",
    "title": "Fact sheet: Health facility coordinator",
    "section": "",
    "text": "As the health facility coordinator on the team, your job is to help your team make informed decisions on the target health facilities (cluster) and study design considerations, including:\n\nSelect appropriate regions and health facilities.\nDecide on the number of clusters (health facilities) to include.\nPlanning for the time it will take to enrol the total number of malaria-positive patients in each location.\n\nNavigate back to the group activity instructions if you need to!\nHealth facility information\nUse the buttons to download as .csv or .xls if you prefer"
  },
  {
    "objectID": "tutorials/module6/sheet_2_tz.html#your-role",
    "href": "tutorials/module6/sheet_2_tz.html#your-role",
    "title": "Fact sheet: Health facility coordinator",
    "section": "",
    "text": "As the health facility coordinator on the team, your job is to help your team make informed decisions on the target health facilities (cluster) and study design considerations, including:\n\nSelect appropriate regions and health facilities.\nDecide on the number of clusters (health facilities) to include.\nPlanning for the time it will take to enrol the total number of malaria-positive patients in each location.\n\nNavigate back to the group activity instructions if you need to!\nHealth facility information\nUse the buttons to download as .csv or .xls if you prefer"
  },
  {
    "objectID": "tutorials/module1/module1_sampling_interactive.html",
    "href": "tutorials/module1/module1_sampling_interactive.html",
    "title": "Module 1: Sampling from a population",
    "section": "",
    "text": "Welcome to Module 1: Sampling from a population.\nIn this module, we‚Äôll explore how to relate samples to populations, calculate confidence intervals, and understand the impact of sample size on study results. We are going to explore how to think about this when conducting studies to determine the prevalence of malaria to start with a simple example to gently introduce these statistical concepts. When we think about malaria molecular surveillance (MMS) studies, the same concepts apply. For example, in MMS studies we might be designing our study to determine the prevalence of molecular markers (for example, drug resistance markers) rather than malaria infection.\n\n\nBy the end of this tutorial, you will be able to:\n\nDefine the target population for a study.\nDifferentiate between a population and a sample.\nCalculate the 95% confidence interval.\nAssess how sampling variability impacts the representation of the population.\nUnderstand the effect of sample size on confidence intervals."
  },
  {
    "objectID": "tutorials/module1/module1_sampling_interactive.html#introduction",
    "href": "tutorials/module1/module1_sampling_interactive.html#introduction",
    "title": "Module 1: Sampling from a population",
    "section": "",
    "text": "Welcome to Module 1: Sampling from a population.\nIn this module, we‚Äôll explore how to relate samples to populations, calculate confidence intervals, and understand the impact of sample size on study results. We are going to explore how to think about this when conducting studies to determine the prevalence of malaria to start with a simple example to gently introduce these statistical concepts. When we think about malaria molecular surveillance (MMS) studies, the same concepts apply. For example, in MMS studies we might be designing our study to determine the prevalence of molecular markers (for example, drug resistance markers) rather than malaria infection.\n\n\nBy the end of this tutorial, you will be able to:\n\nDefine the target population for a study.\nDifferentiate between a population and a sample.\nCalculate the 95% confidence interval.\nAssess how sampling variability impacts the representation of the population.\nUnderstand the effect of sample size on confidence intervals."
  },
  {
    "objectID": "tutorials/module1/module1_sampling_interactive.html#what-is-my-population",
    "href": "tutorials/module1/module1_sampling_interactive.html#what-is-my-population",
    "title": "Module 1: Sampling from a population",
    "section": "What is my population?",
    "text": "What is my population?\nIn any study, clearly defining the target population is crucial. Let‚Äôs consider a few examples of made-up studies.\n\n\nQUIZ - Target population"
  },
  {
    "objectID": "tutorials/module1/module1_sampling_interactive.html#relating-the-sample-to-the-population",
    "href": "tutorials/module1/module1_sampling_interactive.html#relating-the-sample-to-the-population",
    "title": "Module 1: Sampling from a population",
    "section": "Relating the sample to the population",
    "text": "Relating the sample to the population\nIt is often not feasible to sample the entire population, for example, due to costs or difficulty in sampling everyone. The good thing is we can design our study so that our target population is a representative sample of our population.\nOften when designing epidemiological studies, different data sources can provide valuable information on our population, for example a Demographic and Health Survey (DHS) or a population census.\n\nUsing the population census\nLet‚Äôs go back to our made-up study.\nWe now have access to a census of the entire population of the village (N= 10000) with information on each residents age and sex. For purposes of this tutorial we ‚Äúknow‚Äù the true infection status of every individual, there are 2678 people in the village with malaria infections. This will help us understand how our sample relates to the entire population.\nThis is the information we have in the census (here we show the first 6 residents in the census):\n\n\n\n\n\nid\nage\nsex\nmalaria_infection\n\n\n\n\n1\n27\nMale\nNot infected\n\n\n2\n79\nFemale\nNot infected\n\n\n3\n21\nFemale\nInfected\n\n\n4\n8\nFemale\nNot infected\n\n\n5\n4\nMale\nNot infected\n\n\n6\n37\nMale\nInfected\n\n\n\n\n\n\n\nPopulation demographics\nBelow we can see a breakdown of malaria-infected individuals in this population.\n\n\n\n\n\nLet‚Äôs look at the age and sex distribution.\n\n\n\n\n\n\n\nSampling from the population\nSuppose we have resources to sequence 200 samples. Let‚Äôs randomly sample 200 individuals from the population and see how they ‚Äòcompare‚Äô.\nLet‚Äôs take a look at the demographics of our sample by plotting the age and sex distribution of the population and the sample. On the left we have the same age/sex distribution we saw above for the whole population, and on the right we see the distribution in our sampled individuals.\nBelow we use the function sampleFromPopulation() and we specify what our sample size is and from where we want to sample (in our case from the census data).\n\n  Reflection: \n Do we see a similar age and sex distribution? What about the proportion of infected and not infected individuals in the population? \n\n We can use the plotAgeSexDistribution() and plotInfectedProportion() functions to visualize our results. Click on ‚ÄúRun Code‚Äù.\n\n\nsample &lt;- sampleFromPopulation(sample_size = 200, census)\ncomparison &lt;- compareSampleToPopulation(sample, census)\n\nplotAgeSexDistribution(comparison)\n\nplotInfectedProportion(comparison)\n\n\n\n\n\nSampling many times from the population\nNow run this a few times with the sample size of 200 to see how it changes with every random sample. Click ‚ÄúStart Over‚Äù and then ‚ÄúRun code‚Äù.\n\n\nsample &lt;- sampleFromPopulation(sample_size = 200, census)\ncomparison &lt;- compareSampleToPopulation(sample, census)\n\nplotAgeSexDistribution(comparison)\nplotInfectedProportion(comparison)\n\n\n\n\n\nQUIZ - Sampling from the population\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  Reflection: \n Smaller sample sizes are more susceptible to sampling variability. With a limited number of individuals, the likelihood of the sample deviating from the population characteristics increases. Think about how this may or may not impact your results. \n\n\n\n‚ú® BONUS QUESTION ‚ú®\nYou will have noticed from our exploration above that the sample differs from the population and it doesn‚Äôt always have the same age and sex distribution.\n\n\nQUIZ - Sampling bias"
  },
  {
    "objectID": "tutorials/module1/module1_sampling_interactive.html#estimating-prevalence-in-our-sample-and-calculating-the-95-confidence-interval",
    "href": "tutorials/module1/module1_sampling_interactive.html#estimating-prevalence-in-our-sample-and-calculating-the-95-confidence-interval",
    "title": "Module 1: Sampling from a population",
    "section": "Estimating prevalence in our sample and calculating the 95% confidence interval",
    "text": "Estimating prevalence in our sample and calculating the 95% confidence interval\nOur next topic focuses on calculating the 95% confidence interval (CI) using the Wald method. When we estimate the prevalence of malaria in our sample we obtain a point estimate. We also need to calculate its 95% CI to understand the variation around our estimate. The CI provides an interval with lower and upper bounds and in our case, it means that we are 95% confident that the true population prevalence lies within this interval. If we were to repeat the sampling process many times and calculate a confidence interval each time, approximately 95 out of 100 of these intervals would contain the true population prevalence.\nBelow we will learn about the Wald CI formula and how we can calculate it in practice.\n\nEstimating prevalence in our sample\nFor this exercise we have already pre-calculated some useful parameters:\n\nDefined sample_size to be 200\nUsed the function sampleFromPopulation() to select 200 individuals at random from our census\nWe counted the number of infected individuals in our sample and defined it as infected_count (in our example it is 69 individuals)\n\nBelow is the code we ran for reference, but you don‚Äôt have to run it yourself as everything is already loaded.\n\n# set the sample size\nsample_size &lt;- 200\n\n# sample from the population\nsample_data &lt;- sampleFromPopulation(sample_size, census) \n\n# Count number of infected individuals in the sample\ninfected_count &lt;- sum(sample_data$malaria_infection == \"Infected\")\n\n\n\nWhat is the estimated prevalence of malaria in our sample?\nWe can calculate this by dividing the number of individuals infected with malaria by our sample size.\nTry coding it yourself or click on the solution. Note: In R when we want to divide two things we can use /.\n\n\n\n\n\n\n\n69 / 200\n\n# Or you can use the stored variables:\ninfected_count / sample_size\n\n\n\n\nClick to see the answer\n\nOur estimated prevalence is 0.345 or 34.5%.\n\n\nCalculating the 95% CI\nAs we saw above, we need to also calculate the 95% CI around our estimate.\nThis is the Wald confidence interval formula:\n\\[\nCI = \\hat{p} \\pm z_{1 - \\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n\\] Where:\n\n\\(\\hat{p}\\) = sample proportion\n\\(\\ z_{1 - \\alpha/2}\\) = Z-score corresponding to the desired confidence level (for 95%, Z = 1.96)\n\\({n}\\) = sample size\n\nWe are now going to go through this formula step-by-step!\n\n1. Defining our sample proportion, p_hat\nThe sample proportion refers to the proportion of infected individuals in our sample. We just calculated this above by dividing the number of infected individuals in the sample by the total sample size. Let‚Äôs do it again for good measure, and record it as p_hat.\n\n\np_hat &lt;-\n\n\n\n\n\n# Sample proportion\np_hat &lt;- infected_count / sample_size\np_hat\n\n\n\n2. Sample size, n\nAbove we defined our sample size to be n=200 and recorded it as sample_size.\n\n\n3. Calculating the standard error\nNow we can calculate the standard error using p_hat and sample_size. In our formula, the standard error is the part that is multiplied by Z (see below).\n\\[\nSE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n\\]\nNote: In R the function to take the square root is sqrt() and when we want to multiply two things we can use *.\n\n\nSE &lt;- \n\n\n\n\n\n# Standard error\nSE &lt;- sqrt((p_hat * (1 - p_hat)) / sample_size)\nSE\n\n\n\n\nClick to see the answer\n\nOur standard error is 0.336.\n\n\n4. Calculating the confidence interval\nNow that we know our standard error, we can calculate the lower and upper bounds of our 95% CI. We use the Z-score for 95% confidence, which is 1.96 and record it as Z. Then we need to calculate our lower and upper bounds using the formula above. We need to multiply Z by our SE and substract it from p_hat.\nLet‚Äôs start with the lower bound. Click on the solution if you need help.\n\n\n# Z-score for 95% confidence\nZ &lt;- 1.96\n\n# Lower bound\n\n\n\n\n\n# Z-score for 95% confidence\nZ &lt;- 1.96\n\n# Lower bound\np_hat - Z * SE\n\n\n\n\nClick to see the answer\n\nOur lower bound is 0.279 or 27.9%.\n\nNow let‚Äôs calculate the upper bound. Remember now we need to add instead of substract.\n\n\n# Z-score for 95% confidence\nZ &lt;- 1.96\n\n# Upper bound\n\n\n\n\n\n# Z-score for 95% confidence\nZ &lt;- 1.96\n\n# Upper bound\np_hat + Z * SE\n\n\n\n\nClick to see the answer\n\nOur upper bound is 0.411 or 41.1%.\n\nLet‚Äôs put it all together!\n\n\ninfected_count &lt;- 69\nsample_size &lt;- 200\nZ &lt;- 1.96\n\np_hat &lt;- infected_count / sample_size\nSE &lt;- sqrt((p_hat * (1 - p_hat)) / sample_size)\nCI_lower &lt;- p_hat - Z * SE\nCI_upper &lt;- p_hat + Z * SE\n\n# Print our values\np_hat\nCI_lower\nCI_upper\n\n\n\nSo, putting it all together, our estimated prevalence is 0.345 or 34.5% and our 95%CI is 27.9% to 41.1%."
  },
  {
    "objectID": "tutorials/module1/module1_sampling_interactive.html#comparing-to-the-true-prevalence-estimate",
    "href": "tutorials/module1/module1_sampling_interactive.html#comparing-to-the-true-prevalence-estimate",
    "title": "Module 1: Sampling from a population",
    "section": "Comparing to the true prevalence estimate",
    "text": "Comparing to the true prevalence estimate\nYou may remember from our exploration of the census data earlier, that 26.78% of our population was infected with malaria, in others this is the true prevalence.\n\n\nQUIZ - 95% confidence interval\n\n\n\n\n\n\n\n\n\n\n\n\n\n  Reflection: \n Do you always expect the true prevalence to fall within the 95%CI?"
  },
  {
    "objectID": "tutorials/module1/module1_sampling_interactive.html#how-often-does-true-prevalence-fall-within-the-95ci",
    "href": "tutorials/module1/module1_sampling_interactive.html#how-often-does-true-prevalence-fall-within-the-95ci",
    "title": "Module 1: Sampling from a population",
    "section": "How often does true prevalence fall within the 95%CI?",
    "text": "How often does true prevalence fall within the 95%CI?\nWe explored above what would happen if we randomly sampled 200 individuals. In this first example, the true prevalence didn‚Äôt fall within the 95%CI. But this was just one example. Now we want to see what happens if we repeat this sampling many times. Let‚Äôs now explore by running a simulation where we sample 1000 times and we will count how many times our true prevalence is within the 95%CI.\n\n  Reflection: \n Before you run the below code, think about the intuition behind this - how often do you expect the true prevalence to be within the 95%CI? \n\nNow run the code and see if you were correct!\n\n\nn_simulations &lt;- 1000\nsample_size &lt;- 200\n\nresults &lt;- replicate(n_simulations, simulate_CI(census, sample_size, true_prevalence))\n\nplotCISimulationResults(results, n_simulations)\n\n\n\n\n\nQUIZ - Confidence Intervals and Simulation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter running the simulation, you should notice that the true prevalence falls within the 95% confidence intervals in approximately 95% of the simulations. This outcome aligns with the definition of a 95% confidence interval: if we were to repeat the sampling process many times, we would expect the true parameter to lie within the calculated confidence interval about 95 out of 100 times.\n\n  Reflection: \n This simulation demonstrates the concept of confidence level in statistical inference. It shows that the method we use to calculate confidence intervals is reliable in the long run. However, in any single sample (like the one we initially took), there‚Äôs still a chance (about 5%) that the true prevalence will not be captured within the interval. This is why it‚Äôs important to interpret confidence intervals correctly and understand that they provide a measure of the uncertainty associated with our estimates."
  },
  {
    "objectID": "tutorials/module1/module1_sampling_interactive.html#bonus",
    "href": "tutorials/module1/module1_sampling_interactive.html#bonus",
    "title": "Module 1: Sampling from a population",
    "section": "Bonus",
    "text": "Bonus\nNote: This section is optional and requires more coding than the previous exercise\nLet‚Äôs repeat this exercise for a sample size of 500. Try coding it yourself from scratch using the functions that we used above. Click on the solution if you get stuck!\n\n  Reflection: \n Does the true prevalence (26.78%) fall within our 95% CI? What do you notice about the simulation results? \n\n\n\nsample_size &lt;- 500\n\n\n\n\n\nsample_size &lt;- 500\nsample_data &lt;- sampleFromPopulation(sample_size, census)\ncomparison &lt;- compareSampleToPopulation(sample_data, census)\n\nplotAgeSexDistribution(comparison)\nplotInfectedProportion(comparison)\n\ninfected_count &lt;- sum(sample_data$malaria_infection == \"Infected\")\n\np_hat &lt;- infected_count / sample_size\nSE &lt;- sqrt((p_hat * (1 - p_hat)) / sample_size)\nCI_lower &lt;- p_hat - Z * SE\nCI_upper &lt;- p_hat + Z * SE\n\ncheckPrevalenceCI(true_prevalence, CI_lower, CI_upper)\n\nn_simulations &lt;- 1000\nresults &lt;- replicate(n_simulations, simulate_CI(census, sample_size, true_prevalence))\nplotCISimulationResults(results, n_simulations)"
  }
]